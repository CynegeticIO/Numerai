{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Model.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyOay3UO0jwCvXQKIh3nRxw2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"GjYh7u4jsWul"},"source":["Created by Joan-Marc Fisa\n","\n","- Numerai: [FisaGol](https://numer.ai/fisagol)\n","\n","- Twitter: [@fisagol](https://twitter.com/fisagol)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DiVYHQNwKsPc","executionInfo":{"status":"ok","timestamp":1631391482767,"user_tz":-120,"elapsed":339,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}},"outputId":"3b27b9a8-4f3b-4e6f-d4e5-ab6506a54457"},"source":["from google.colab import drive\n","drive.mount('drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"gbiUg0x-mrzx"},"source":["# https://www.kaggle.com/kansukehabano/numerai-training-new-data-for-low-ram"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ywcs8DyDvCl4","executionInfo":{"status":"ok","timestamp":1631391492396,"user_tz":-120,"elapsed":9197,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}},"outputId":"74be2554-91a3-4b93-a743-772c4a3b50d9"},"source":["!pip install numerapi\n","!pip install halo\n","!pip install vecstack;"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numerapi in /usr/local/lib/python3.7/dist-packages (2.8.1)\n","Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from numerapi) (1.1.5)\n","Requirement already satisfied: tqdm>=4.29.1 in /usr/local/lib/python3.7/dist-packages (from numerapi) (4.62.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from numerapi) (2.23.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from numerapi) (2.8.2)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from numerapi) (2018.9)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from numerapi) (7.1.2)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->numerapi) (1.19.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->numerapi) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (2.10)\n","Requirement already satisfied: halo in /usr/local/lib/python3.7/dist-packages (0.0.31)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from halo) (1.1.0)\n","Requirement already satisfied: colorama>=0.3.9 in /usr/local/lib/python3.7/dist-packages (from halo) (0.4.4)\n","Requirement already satisfied: log-symbols>=0.0.14 in /usr/local/lib/python3.7/dist-packages (from halo) (0.0.14)\n","Requirement already satisfied: spinners>=0.0.24 in /usr/local/lib/python3.7/dist-packages (from halo) (0.0.24)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from halo) (1.15.0)\n","Requirement already satisfied: vecstack in /usr/local/lib/python3.7/dist-packages (0.4.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.19.5)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from vecstack) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->vecstack) (1.0.1)\n"]}]},{"cell_type":"code","metadata":{"id":"pt1mlLEL8fLZ","executionInfo":{"status":"ok","timestamp":1631391493670,"user_tz":-120,"elapsed":1281,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}}},"source":["import os\n","import requests\n","import numpy as np\n","import pandas as pd\n","import scipy\n","from halo import Halo\n","from pathlib import Path\n","import json\n","from scipy.stats import skew, kurtosis\n","from lightgbm import LGBMRegressor, Dataset, train\n","import gc\n","from numerapi import NumerAPI\n","from sklearn import (\n","    feature_extraction, feature_selection, decomposition, linear_model,\n","    model_selection, metrics, svm\n",")\n","\n","ERA_COL = \"era\"\n","TARGET_COL = \"target\"\n","spinner = Halo(text='', spinner='dots')\n","\n","MODEL_FOLDER = \"models\"\n","MODEL_CONFIGS_FOLDER = \"model_configs\"\n","PREDICTION_FILES_FOLDER = \"prediction_files\""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"lHuSrsMg8fNS","executionInfo":{"status":"ok","timestamp":1631391494297,"user_tz":-120,"elapsed":628,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}}},"source":["\n","def save_model(model, name):\n","    try:\n","        Path(MODEL_FOLDER).mkdir(exist_ok=True, parents=True)\n","    except Exception as ex:\n","        pass\n","    pd.to_pickle(model, f\"{MODEL_FOLDER}/{name}.pkl\")\n","\n","\n","def load_model(name):\n","    path = Path(f\"{MODEL_FOLDER}/{name}.pkl\")\n","    if path.is_file():\n","        model = pd.read_pickle(f\"{MODEL_FOLDER}/{name}.pkl\")\n","    else:\n","        model = False\n","    return model\n","\n","\n","def save_model_config(model_config, model_name):\n","    try:\n","        Path(MODEL_CONFIGS_FOLDER).mkdir(exist_ok=True, parents=True)\n","    except Exception as ex:\n","        pass\n","    with open(f\"{MODEL_CONFIGS_FOLDER}/{model_name}.json\", 'w') as fp:\n","        json.dump(model_config, fp)\n","\n","\n","def load_model_config(model_name):\n","    path_str = f\"{MODEL_CONFIGS_FOLDER}/{model_name}.json\"\n","    path = Path(path_str)\n","    if path.is_file():\n","        with open(path_str, 'r') as fp:\n","            model_config = json.load(fp)\n","    else:\n","        model_config = False\n","    return model_config\n","\n","\n","def get_biggest_change_features(corrs, n):\n","    all_eras = corrs.index.sort_values()\n","    h1_eras = all_eras[:len(all_eras) // 2]\n","    h2_eras = all_eras[len(all_eras) // 2:]\n","\n","    h1_corr_means = corrs.loc[h1_eras, :].mean()\n","    h2_corr_means = corrs.loc[h2_eras, :].mean()\n","\n","    corr_diffs = h2_corr_means - h1_corr_means\n","    worst_n = corr_diffs.abs().sort_values(ascending=False).head(n).index.tolist()\n","    return worst_n\n","\n","\n","def get_time_series_cross_val_splits(data, cv = 3, embargo = 12):\n","    all_train_eras = data[ERA_COL].unique()\n","    len_split = len(all_train_eras) // cv\n","    test_splits = [all_train_eras[i * len_split:(i + 1) * len_split] for i in range(cv)]\n","    # fix the last test split to have all the last eras, in case the number of eras wasn't divisible by cv\n","    test_splits[-1] = np.append(test_splits[-1], all_train_eras[-1])\n","\n","    train_splits = []\n","    for test_split in test_splits:\n","        test_split_max = int(np.max(test_split))\n","        test_split_min = int(np.min(test_split))\n","        # get all of the eras that aren't in the test split\n","        train_split_not_embargoed = [e for e in all_train_eras if not (test_split_min <= int(e) <= test_split_max)]\n","        # embargo the train split so we have no leakage.\n","        # one era is length 5, so we need to embargo by target_length/5 eras.\n","        # To be consistent for all targets, let's embargo everything by 60/5 == 12 eras.\n","        train_split = [e for e in train_split_not_embargoed if\n","                       abs(int(e) - test_split_max) > embargo and abs(int(e) - test_split_min) > embargo]\n","        train_splits.append(train_split)\n","\n","    # convenient way to iterate over train and test splits\n","    train_test_zip = zip(train_splits, test_splits)\n","    return train_test_zip\n","\n","\n","def neutralize(df,\n","               columns,\n","               neutralizers=None,\n","               proportion=1.0,\n","               normalize=True,\n","               era_col=\"era\"):\n","    if neutralizers is None:\n","        neutralizers = []\n","    unique_eras = df[era_col].unique()\n","    computed = []\n","    for u in unique_eras:\n","        df_era = df[df[era_col] == u]\n","        scores = df_era[columns].values\n","        if normalize:\n","            scores2 = []\n","            for x in scores.T:\n","                x = (scipy.stats.rankdata(x, method='ordinal') - .5) / len(x)\n","                x = scipy.stats.norm.ppf(x)\n","                scores2.append(x)\n","            scores = np.array(scores2).T\n","        exposures = df_era[neutralizers].values\n","\n","        scores -= proportion * exposures.dot(\n","            np.linalg.pinv(exposures.astype(np.float32)).dot(scores.astype(np.float32)))\n","\n","        scores /= scores.std(ddof=0)\n","\n","        computed.append(scores)\n","\n","    return pd.DataFrame(np.concatenate(computed),\n","                        columns=columns,\n","                        index=df.index)\n","\n","\n","def neutralize_series(series, by, proportion=1.0):\n","    scores = series.values.reshape(-1, 1)\n","    exposures = by.values.reshape(-1, 1)\n","\n","    # this line makes series neutral to a constant column so that it's centered and for sure gets corr 0 with exposures\n","    exposures = np.hstack(\n","        (exposures,\n","         np.array([np.mean(series)] * len(exposures)).reshape(-1, 1)))\n","\n","    correction = proportion * (exposures.dot(\n","        np.linalg.lstsq(exposures, scores, rcond=None)[0]))\n","    corrected_scores = scores - correction\n","    neutralized = pd.Series(corrected_scores.ravel(), index=series.index)\n","    return neutralized\n","\n","\n","def unif(df):\n","    x = (df.rank(method=\"first\") - 0.5) / len(df)\n","    return pd.Series(x, index=df.index)\n","\n","\n","def get_feature_neutral_mean(df, prediction_col):\n","    feature_cols = [c for c in df.columns if c.startswith(\"feature\")]\n","    df.loc[:, \"neutral_sub\"] = neutralize(df, [prediction_col],\n","                                          feature_cols)[prediction_col]\n","    scores = df.groupby(\"era\").apply(\n","        lambda x: (unif(x[\"neutral_sub\"]).corr(x[TARGET_COL]))).mean()\n","    return np.mean(scores)\n","\n","\n","def fast_score_by_date(df, columns, target, tb=None, era_col=\"era\"):\n","    unique_eras = df[era_col].unique()\n","    computed = []\n","    for u in unique_eras:\n","        df_era = df[df[era_col] == u]\n","        era_pred = np.float64(df_era[columns].values.T)\n","        era_target = np.float64(df_era[target].values.T)\n","\n","        if tb is None:\n","            ccs = np.corrcoef(era_target, era_pred)[0, 1:]\n","        else:\n","            tbidx = np.argsort(era_pred, axis=1)\n","            tbidx = np.concatenate([tbidx[:, :tb], tbidx[:, -tb:]], axis=1)\n","            ccs = [np.corrcoef(era_target[tmpidx], tmppred[tmpidx])[0, 1] for tmpidx, tmppred in zip(tbidx, era_pred)]\n","            ccs = np.array(ccs)\n","\n","        computed.append(ccs)\n","\n","    return pd.DataFrame(np.array(computed), columns=columns, index=df[era_col].unique())\n","\n","\n","def validation_metrics(validation_data, pred_cols, example_col, fast_mode=False):\n","    validation_stats = pd.DataFrame()\n","    feature_cols = [c for c in validation_data if c.startswith(\"feature_\")]\n","    for pred_col in pred_cols:\n","        # Check the per-era correlations on the validation set (out of sample)\n","        validation_correlations = validation_data.groupby(ERA_COL).apply(\n","            lambda d: unif(d[pred_col]).corr(d[TARGET_COL]))\n","\n","        mean = validation_correlations.mean()\n","        std = validation_correlations.std(ddof=0)\n","        sharpe = mean / std\n","\n","        validation_stats.loc[\"mean\", pred_col] = mean\n","        validation_stats.loc[\"std\", pred_col] = std\n","        validation_stats.loc[\"sharpe\", pred_col] = sharpe\n","\n","        rolling_max = (validation_correlations + 1).cumprod().rolling(window=9000,  # arbitrarily large\n","                                                                      min_periods=1).max()\n","        daily_value = (validation_correlations + 1).cumprod()\n","        max_drawdown = -((rolling_max - daily_value) / rolling_max).max()\n","        validation_stats.loc[\"max_drawdown\", pred_col] = max_drawdown\n","\n","        payout_scores = validation_correlations.clip(-0.25, 0.25)\n","        payout_daily_value = (payout_scores + 1).cumprod()\n","\n","        apy = (\n","            (\n","                (payout_daily_value.dropna().iloc[-1])\n","                ** (1 / len(payout_scores))\n","            )\n","            ** 49  # 52 weeks of compounding minus 3 for stake compounding lag\n","            - 1\n","        ) * 100\n","\n","        validation_stats.loc[\"apy\", pred_col] = apy\n","\n","        if not fast_mode:\n","            # Check the feature exposure of your validation predictions\n","            max_per_era = validation_data.groupby(ERA_COL).apply(\n","                lambda d: d[feature_cols].corrwith(d[pred_col]).abs().max())\n","            max_feature_exposure = max_per_era.mean()\n","            validation_stats.loc[\"max_feature_exposure\", pred_col] = max_feature_exposure\n","\n","            # Check feature neutral mean\n","            feature_neutral_mean = get_feature_neutral_mean(validation_data, pred_col)\n","            validation_stats.loc[\"feature_neutral_mean\", pred_col] = feature_neutral_mean\n","\n","            # Check top and bottom 200 metrics (TB200)\n","            tb200_validation_correlations = fast_score_by_date(\n","                validation_data,\n","                [pred_col],\n","                TARGET_COL,\n","                tb=200,\n","                era_col=ERA_COL\n","            )\n","\n","            tb200_mean = tb200_validation_correlations.mean()[pred_col]\n","            tb200_std = tb200_validation_correlations.std(ddof=0)[pred_col]\n","            tb200_sharpe = mean / std\n","\n","            validation_stats.loc[\"tb200_mean\", pred_col] = tb200_mean\n","            validation_stats.loc[\"tb200_std\", pred_col] = tb200_std\n","            validation_stats.loc[\"tb200_sharpe\", pred_col] = tb200_sharpe\n","\n","        # MMC over validation\n","        mmc_scores = []\n","        corr_scores = []\n","        for _, x in validation_data.groupby(ERA_COL):\n","            series = neutralize_series(unif(x[pred_col]), (x[example_col]))\n","            mmc_scores.append(np.cov(series, x[TARGET_COL])[0, 1] / (0.29 ** 2))\n","            corr_scores.append(unif(x[pred_col]).corr(x[TARGET_COL]))\n","\n","        val_mmc_mean = np.mean(mmc_scores)\n","        val_mmc_std = np.std(mmc_scores)\n","        corr_plus_mmcs = [c + m for c, m in zip(corr_scores, mmc_scores)]\n","        corr_plus_mmc_sharpe = np.mean(corr_plus_mmcs) / np.std(corr_plus_mmcs)\n","\n","        validation_stats.loc[\"mmc_mean\", pred_col] = val_mmc_mean\n","        validation_stats.loc[\"corr_plus_mmc_sharpe\", pred_col] = corr_plus_mmc_sharpe\n","\n","        # Check correlation with example predictions\n","        per_era_corrs = validation_data.groupby(ERA_COL).apply(lambda d: unif(d[pred_col]).corr(unif(d[example_col])))\n","        corr_with_example_preds = per_era_corrs.mean()\n","        validation_stats.loc[\"corr_with_example_preds\", pred_col] = corr_with_example_preds\n","\n","    # .transpose so that stats are columns and the model_name is the row\n","    return validation_stats.transpose()\n","\n","\n","def download_data(napi, filename, dest_path):\n","    spinner.start(f'Downloading {dest_path}')\n","    napi.download_dataset(filename, dest_path)\n","    spinner.succeed()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"xmjpMpXg-ZwO","executionInfo":{"status":"ok","timestamp":1631391494298,"user_tz":-120,"elapsed":2,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}}},"source":["##############################################################################\n","##############################################################################\n","##############################################################################"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"238SZPqE8fO_","executionInfo":{"status":"ok","timestamp":1631391494589,"user_tz":-120,"elapsed":293,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}}},"source":["\n","napi = NumerAPI()\n","spinner = Halo(text='', spinner='dots')\n","\n","current_round = napi.get_current_round(tournament=8)  # tournament 8 is the primary Numerai Tournament"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"caEmCNZkMN1w","executionInfo":{"status":"ok","timestamp":1631391494589,"user_tz":-120,"elapsed":3,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}},"outputId":"253e0355-06ca-461b-ecee-344de91baa95"},"source":["current_round"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["281"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IM6SfoAs-iWH","executionInfo":{"status":"ok","timestamp":1631391496857,"user_tz":-120,"elapsed":2269,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}},"outputId":"eefec3f1-d4ef-451b-abe2-027a586228f3"},"source":["\n","# read in all of the new datas\n","# tournament data and example predictions change every week so we specify the round in their names\n","# training and validation data only change periodically, so no need to download them over again every single week\n","napi.download_dataset(\"numerai_training_data.parquet\", \"numerai_training_data.parquet\")\n","napi.download_dataset(\"numerai_tournament_data.parquet\", f\"numerai_tournament_data_{current_round}.parquet\")\n","# napi.download_dataset(\"numerai_validation_data.parquet\", f\"numerai_validation_data.parquet\")\n","# napi.download_dataset(\"example_predictions.parquet\", f\"example_predictions_{current_round}.parquet\")\n","# napi.download_dataset(\"example_validation_predictions.parquet\", \"example_validation_predictions.parquet\")\n"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["2021-09-11 20:18:15,486 INFO numerapi.utils: target file already exists\n","2021-09-11 20:18:15,488 INFO numerapi.utils: download complete\n","2021-09-11 20:18:16,421 INFO numerapi.utils: target file already exists\n","2021-09-11 20:18:16,423 INFO numerapi.utils: download complete\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AEfut8d2-lEC","executionInfo":{"status":"ok","timestamp":1631391530850,"user_tz":-120,"elapsed":33996,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}},"outputId":"c596e2f5-3477-451b-970b-092e0bea744d"},"source":["spinner.start('Reading parquet data')\n","training_data = pd.read_parquet('numerai_training_data.parquet')\n","tournament_data = pd.read_parquet(f'numerai_tournament_data_{current_round}.parquet')\n","# validation_data = pd.read_parquet('numerai_validation_data.parquet')\n","# example_preds = pd.read_parquet(f'example_predictions_{current_round}.parquet')\n","# validation_preds = pd.read_parquet('example_validation_predictions.parquet')\n","spinner.succeed()"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["✔ Reading parquet data\n"]},{"output_type":"execute_result","data":{"text/plain":["<halo.halo.Halo at 0x7f720528da50>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"82z11oT7-oLO","executionInfo":{"status":"ok","timestamp":1631391530850,"user_tz":-120,"elapsed":27,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}}},"source":["EXAMPLE_PREDS_COL = \"example_preds\"\n","\n","TARGET_COL = \"target\"\n","ERA_COL = \"era\""],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dkcD5FWZ-rI2","executionInfo":{"status":"ok","timestamp":1631391530851,"user_tz":-120,"elapsed":26,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}},"outputId":"99573e1e-6982-4651-a4e3-ef63b6f916c7"},"source":["# all feature columns start with the prefix \"feature_\"\n","feature_cols = [c for c in training_data if c.startswith(\"feature_\")]\n","gc.collect()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["100"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zqzcL8EKDF4x","executionInfo":{"status":"ok","timestamp":1631391530851,"user_tz":-120,"elapsed":21,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}},"outputId":"f8883b98-ab23-4943-c4e1-0051cdc312f5"},"source":["targets = [c for c in training_data if c.startswith(\"target\")]\n","gc.collect()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["50"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w52Ni7HPDBaY","executionInfo":{"status":"ok","timestamp":1631391530851,"user_tz":-120,"elapsed":19,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}},"outputId":"71e50c43-ab78-4124-d8d0-e58025612020"},"source":["training_data[\"erano\"] = training_data.era.astype(int)\n","eras = training_data.erano\n","training_target = training_data[TARGET_COL]\n","gc.collect()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["50"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"87w4di8lcS22","executionInfo":{"status":"ok","timestamp":1631391535132,"user_tz":-120,"elapsed":4296,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}}},"source":["training_data = training_data.drop(targets, axis=1)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"wQAGp7uMcluF","executionInfo":{"status":"ok","timestamp":1631391535134,"user_tz":-120,"elapsed":18,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}}},"source":["training_data[TARGET_COL] = training_target.values"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mw_g9zutbe0Y","executionInfo":{"status":"ok","timestamp":1631391548816,"user_tz":-120,"elapsed":13699,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}},"outputId":"05139142-1ddc-401c-f067-2e84b3185572"},"source":["df = [d for k, d in training_data.groupby(training_data['erano']//41)]\n","gc.collect()"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["2021-09-11 20:18:54,357 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n"]},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"5R10ppF6bHuM","executionInfo":{"status":"ok","timestamp":1631391602389,"user_tz":-120,"elapsed":305,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}}},"source":["df1 = df[0]\n","df2 = df[1]\n","df3 = df[2]\n","df4 = df[3]\n","df5 = df[4]\n","df6 = df[5]\n","df7 = df[6]\n","df8 = df[7]\n","df9 = df[8]\n","df10 = df[9]\n","df11 = df[10]\n","df12 = df[11]\n","df13 = df[12]\n","df14 = df[13]\n","df15 = df[14]"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EBvFG84NbHwG","executionInfo":{"status":"ok","timestamp":1631391940839,"user_tz":-120,"elapsed":22721,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}},"outputId":"ce8ed801-8174-4002-c880-4c067169b9bf"},"source":["lgb1 = LGBMRegressor()\n","lgb1.fit(df1[feature_cols], df1[TARGET_COL])\n","gc.collect()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n","              importance_type='split', learning_rate=0.1, max_depth=-1,\n","              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n","              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n","              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n","              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"aafTEYUbbHyK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mHVnPsMRLMV2","executionInfo":{"status":"ok","timestamp":1631389430594,"user_tz":-120,"elapsed":5779,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}}},"source":["df1 = training_data[eras<=eras.median()]\n","df2 = training_data[eras>eras.median()]"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"k4aPZ65xLqlF","executionInfo":{"status":"ok","timestamp":1631389521542,"user_tz":-120,"elapsed":484,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00374894131735723747"}}},"source":["# Train a standard xgboost on half the train eras\n","lgb = LGBMRegressor(linear_tree='true')"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"oC21gB33LMbb"},"source":["lgb.fit(df1[feature_cols], df1[TARGET_COL])\n","gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"29BOnJuRLMdY"},"source":["\n","lgb_preds = lgb.predict(df2[feature_cols])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DDlEggfwD-mv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SG6YMkns-smy","outputId":"bcb3e16e-f767-474c-9d63-32a06bae5df5"},"source":["model_name = f\"model_target\"\n","print(f\"predicting {model_name}\")\n","model = LGBMRegressor()\n","# train on all of train, predict on val, predict on tournament, save the model so we don't have to train next time\n","spinner.start('Training model')\n","model.fit(training_data[feature_cols], training_data[TARGET_COL])\n","spinner.succeed()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["predicting model_target\n","model not found, training new one\n"]}]},{"cell_type":"code","metadata":{"id":"u8ppy-IG-vDa"},"source":["# check for nans and fill nans\n","if tournament_data.loc[tournament_data[\"data_type\"] == \"live\", feature_cols].isna().sum().sum():\n","    cols_w_nan = tournament_data.loc[tournament_data[\"data_type\"] == \"live\", feature_cols].isna().sum()\n","    total_rows = tournament_data[tournament_data[\"data_type\"] == \"live\"]\n","    print(f\"Number of nans per column this week: {cols_w_nan[cols_w_nan > 0]}\")\n","    print(f\"out of {total_rows} total rows\")\n","    print(f\"filling nans with 0.5\")\n","    tournament_data.loc[:, feature_cols].fillna(0.5, inplace=True)\n","else:\n","    print(\"No nans in the features this week!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SQizY80t-wXO"},"source":["# predict on the latest data!\n","spinner.start('Predicting on latest data')\n","# double check the feature that the model expects vs what is available\n","# this prevents our pipeline from failing if Numerai adds more data and we don't have time to retrain!\n","model_expected_features = model.booster_.feature_name()\n","if set(model_expected_features) != set(feature_cols):\n","    print(f\"New features are available! Might want to retrain model {model_name}.\")\n","validation_data.loc[:, f\"preds_{model_name}\"] = model.predict(validation_data.loc[:, model_expected_features])\n","tournament_data.loc[:, f\"preds_{model_name}\"] = model.predict(tournament_data.loc[:, model_expected_features])\n","\n","spinner.succeed()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A79g-bDj-xd9"},"source":["spinner.start('Neutralizing to risky features')\n","# getting the per era correlation of each feature vs the target\n","all_feature_corrs = training_data.groupby(ERA_COL).apply(lambda d: d[feature_cols].corrwith(d[TARGET_COL]))\n","\n","# find the riskiest features by comparing their correlation vs the target in half 1 and half 2 of training data\n","riskiest_features = get_biggest_change_features(all_feature_corrs, 50)\n","\n","# neutralize our predictions to the riskiest features\n","validation_data[f\"preds_{model_name}_neutral_riskiest_50\"] = neutralize(df=validation_data,\n","                                                                        columns=[f\"preds_{model_name}\"],\n","                                                                        neutralizers=riskiest_features,\n","                                                                        proportion=1.0,\n","                                                                        normalize=True,\n","                                                                        era_col=ERA_COL)\n","\n","tournament_data[f\"preds_{model_name}_neutral_riskiest_50\"] = neutralize(df=tournament_data,\n","                                                                        columns=[f\"preds_{model_name}\"],\n","                                                                        neutralizers=riskiest_features,\n","                                                                        proportion=1.0,\n","                                                                        normalize=True,\n","                                                                        era_col=ERA_COL)\n","spinner.succeed()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xrMfrKcc-yxZ"},"source":["model_to_submit = f\"preds_{model_name}_neutral_riskiest_50\"\n","# rename best model to prediction and rank from 0 to 1 to meet diagnostic/submission file requirements\n","validation_data[\"prediction\"] = validation_data[model_to_submit].rank(pct=True)\n","tournament_data[\"prediction\"] = tournament_data[model_to_submit].rank(pct=True)\n","validation_data[\"prediction\"].to_csv(f\"validation_predictions_{current_round}.csv\")\n","tournament_data[\"prediction\"].to_csv(f\"tournament_predictions_{current_round}.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L61Fgr4T-1D9"},"source":["# get some stats about each of our models to compare...\n","# fast_mode=True so that we skip some of the stats that are slower to calculate\n","validation_stats = validation_metrics(validation_data, [model_to_submit], example_col=EXAMPLE_PREDS_COL, fast_mode=True)\n","print(validation_stats[[\"mean\", \"sharpe\"]].to_markdown())"],"execution_count":null,"outputs":[]}]}