{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"provenance":[{"file_id":"1YX3IgXCPCrc7sdOipG0lykuLAbhE8OVD","timestamp":1610197629253},{"file_id":"1qZ9MXaezKO4_uLd8Clq4HSkd9y2-DVvU","timestamp":1608315596921},{"file_id":"1k0Iv2X-_z35Pbf1tIBCUTovWRO2O1aRJ","timestamp":1607364747831},{"file_id":"1dWjWFBakLacyJ1_C8l6ZituGItKWezJE","timestamp":1607177919869},{"file_id":"https://github.com/parmarsuraj99/numerai-guides/blob/master/better_evaluation/Numerai_evaluate_better.ipynb","timestamp":1606918739349}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"GjYh7u4jsWul"},"source":["Created by Joan-Marc Fisa\n","\n","- Numerai: [FisaGol](https://numer.ai/fisagol)\n","\n","- Twitter: [@fisagol](https://twitter.com/fisagol)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dukzbOx5YPL2","executionInfo":{"status":"ok","timestamp":1631116304080,"user_tz":-120,"elapsed":3910,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"7ff06db0-8c05-4486-f5df-1f75d2fae626"},"source":["!pip install numerapi"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting numerapi\n","  Downloading numerapi-2.8.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: tqdm>=4.29.1 in /usr/local/lib/python3.7/dist-packages (from numerapi) (4.62.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from numerapi) (2.23.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from numerapi) (2.8.2)\n","Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from numerapi) (1.1.5)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from numerapi) (2018.9)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from numerapi) (7.1.2)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->numerapi) (1.19.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->numerapi) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (2.10)\n","Installing collected packages: numerapi\n","Successfully installed numerapi-2.8.0\n"]}]},{"cell_type":"code","metadata":{"id":"S-llL1U4drNA"},"source":["##################################################################\n","##################### LIBRARIES ##################################\n","##################################################################\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L3qA9k0VZ4Hj"},"source":["import os\n","import gc\n","import csv\n","import sys\n","import glob\n","import time\n","from pathlib import Path\n","from multiprocessing import Pool\n","\n","import numerapi\n","\n","import scipy\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import random\n","import sklearn\n","from sklearn import (\n","    feature_extraction, feature_selection, decomposition, linear_model,\n","    model_selection, metrics, svm, preprocessing, utils\n",")\n","from sklearn.preprocessing import StandardScaler,MinMaxScaler, OrdinalEncoder, LabelEncoder,OneHotEncoder\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, GridSearchCV,cross_val_score,KFold, RepeatedStratifiedKFold,train_test_split\n","from sklearn.metrics import log_loss, make_scorer, mean_squared_error,classification_report,accuracy_score\n","from sklearn import preprocessing\n","from xgboost import XGBRegressor \n","from sklearn.cluster import KMeans\n","import matplotlib as plt\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler,MinMaxScaler\n","\n","import math\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.models import Model\n","from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, BaggingRegressor\n","from sklearn.linear_model import SGDRegressor\n","from lightgbm import LGBMRegressor\n","from sklearn.tree import DecisionTreeRegressor \n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from sklearn import metrics\n","\n","from scipy import stats\n","\n","def RMSLE(y, pred):\n","    return metrics.mean_squared_error(y, pred) ** 0.5\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oGMB_CBrrwii","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1612724709434,"user_tz":-60,"elapsed":22593,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"1a2245a6-904c-4273-9916-5cebb10872c8"},"source":["'''\n","# R \n","\n","random_slicer <- function(features, slice_percent){\n","\n","  train_slice <- features[,4:313]\n","  feat_list <- sort(sample(1:310,round(310*slice_percent)))\n","\n","  for(i in length(feat_list)){\n","      train_slice[,feat_list[i]] <- (-1)*(train_slice[,feat_list[i]] - 0.5) + 0.5\n","  }    \n","  train_slice  \n","}\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n# R \\n\\nrandom_slicer <- function(features, slice_percent){\\n\\n  train_slice <- features[,4:313]\\n  feat_list <- sort(sample(1:310,round(310*slice_percent)))\\n\\n  for(i in length(feat_list)){\\n      train_slice[,feat_list[i]] <- (-1)*(train_slice[,feat_list[i]] - 0.5) + 0.5\\n  }    \\n  train_slice  \\n}\\n'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"CmGYfuWdElvN"},"source":["##############################################################################\n","########################## DOWLOAD DATA ######################################\n","##############################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HPqlpE4-d0G0"},"source":["seed = 3\n","rand = np.random.seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HrzPVfR6egjj","executionInfo":{"status":"ok","timestamp":1625249426197,"user_tz":-120,"elapsed":29482,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"39a0ef66-8e73-47ce-e7b6-4b806b5a0345"},"source":["napi = numerapi.NumerAPI(verbosity=\"info\")\n","\n","napi.download_current_dataset(unzip=True)\n","\n","current_ds = napi.get_current_round()\n","latest_round = os.path.join('numerai_dataset_'+str(current_ds))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-07-02 18:09:47,226 INFO numerapi.utils: starting download\n","./numerai_dataset_270.zip: 410MB [00:09, 44.2MB/s]                           \n","2021-07-02 18:09:56,509 INFO numerapi.base_api: unzipping file...\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"taUitEnG4UXe"},"source":["##################################################################\n","##################### LOAD DATA ##################################\n","##################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VgodzImqq7z3","executionInfo":{"status":"ok","timestamp":1625249678005,"user_tz":-120,"elapsed":89557,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"3da609f9-0fb5-4aff-812d-8187e6199dcf"},"source":["%%time\n","print(\"# Loading data...\")\n","\n","training_data = pd.read_csv(os.path.join(latest_round, \"numerai_training_data.csv\")).set_index(\"id\")\n","tournament_data = pd.read_csv(os.path.join(latest_round, \"numerai_tournament_data.csv\")).set_index(\"id\")\n","validation_data = tournament_data[tournament_data.data_type == \"validation\"]\n","\n","print(\"# All Loaded...\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["# Loading data...\n","# All Loaded...\n","CPU times: user 1min 18s, sys: 8.68 s, total: 1min 27s\n","Wall time: 1min 29s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gKGYq1Ce7MHX","executionInfo":{"status":"ok","timestamp":1625249829765,"user_tz":-120,"elapsed":243,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"4268e9d7-872a-4d43-c3c6-b2559880291e"},"source":["feature_names = [f for f in training_data.columns if f.startswith(\"feature\")]\n","print(f\"Loaded {len(feature_names)} features\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loaded 310 features\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e_D_jNfBHyNc"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nsPNZrq_PI6_"},"source":["'''\n","##################### CLASSES AND FUNCTIONS ##################################\n","'''\n","def my_loss_fn(y_true, y_pred):\n","    squared_difference = tf.square(y_true - y_pred)\n","    return tf.reduce_mean(squared_difference, axis=-1)\n","\n","def standardize_data(df):\n","    scaler = RobustScaler()\n","    data = scaler.fit_transform(df)\n","    return data\n","\n","def my_loss_fn_1(y_true, y_pred):\n","    loss = tf.keras.losses.poisson(y_true, y_pred)\n","    return loss\n","\n","\n","def my_loss_fn_2(y_true, y_pred):\n","    threshold = 1     \n","    error = y_true - y_pred     \n","    is_small_error = tf.abs(error) <= threshold     \n","    small_error_loss = tf.square(error) / 2     \n","    big_error_loss = threshold * (tf.abs(error) - (0.5 * threshold))\n","    return tf.where(is_small_error, small_error_loss, big_error_loss)\n","\n","def my_loss_fn_3(y_true, y_pred):\n","    squared_difference = tf.square(y_true - y_pred)\n","    return tf.reduce_mean(squared_difference, axis=-1)\n","\n","\n","def rank_correlation(y_true, y_pred):\n","    return np.nan_to_num(stats.spearmanr(y_true, y_pred, axis=1)[0], nan=-1)\n","\n","\n","def rmsle_1(y_true, y_pred):\n","    return 'RMSLE', np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2))), False\n","\n","def rae_1(y_true, y_pred):\n","    return 'RAE', np.sum(np.abs(y_pred - y_true)) / np.sum(np.abs(np.mean(y_true) - y_true)), False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BsGeGhAeNBoA"},"source":["import torch\n","from torch.autograd import grad\n","\n","# define adjusted sharpe in terms of cost adjusted numerai sharpe\n","def numerai_sharpe(x):\n","    return (x.mean() -0.010415154) / x.std()\n","\n","def skew(x):\n","    mx = x.mean()\n","    m2 = ((x-mx)**2).mean()\n","    m3 = ((x-mx)**3).mean()\n","    return m3/(m2**1.5)    \n","\n","def kurtosis(x):\n","    mx = x.mean()\n","    m4 = ((x-mx)**4).mean()\n","    m2 = ((x-mx)**2).mean()\n","    return (m4/(m2**2))-3\n","\n","def adj_sharpe(x):\n","    return numerai_sharpe(x) * (1 + ((skew(x) / 6) * numerai_sharpe(x)) - ((kurtosis(x) / 24) * (numerai_sharpe(x) ** 2)))\n","\n","# use correlation as the measure of fit\n","def corr(pred, target):\n","    pred_n = pred - pred.mean(dim=0)\n","    pred_n = pred_n / pred_n.norm(dim=0)\n","\n","    target_n = target - target.mean(dim=0)\n","    target_n = target_n / target_n.norm(dim=0)\n","    l = torch.matmul(pred_n.T, target_n)\n","    return l\n","\n","# definte a custom objective for XGBoost\n","def adj_sharpe_obj(ytrue, ypred):\n","    # convert to pytorch tensors\n","    ypred_th = torch.tensor(ypred, requires_grad=True)\n","    ytrue_th = torch.tensor(ytrue)\n","    all_corrs = []\n","\n","    # get correlations in each era\n","    for ee in era_idx:\n","        score = corr(ypred_th[ee], ytrue_th[ee])\n","        all_corrs.append(score)\n","\n","    all_corrs = torch.stack(all_corrs)\n","\n","    # calculate adjusted sharpe using correlations\n","    loss = -adj_sharpe(all_corrs)\n","    print(f'Current loss:{loss}')\n","\n","    # calculate gradient and convert to numpy\n","    loss_grads = grad(loss, ypred_th, create_graph=True)[0]\n","    loss_grads = loss_grads.detach().numpy()\n","\n","    # return gradient and ones instead of Hessian diagonal\n","    return loss_grads, np.ones(loss_grads.shape)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aRnCIHEmIN6V"},"source":["#############################################################################\n","########################   PREPARE DATA   ###################################\n","#############################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RCITMekwZt4O"},"source":["X = training_data[feature_names]\n","Y = training_data[training_data.columns[-1]]\n","\n","le = LabelEncoder()\n","Y_enc = le.fit_transform(Y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tHATa1jEq01J"},"source":["#https://forum.numer.ai/t/model-diagnostics-risk-metrics/900\n","\n","TOURNAMENT_NAME = \"nomi\"\n","TARGET_NAME = f\"target\"\n","PREDICTION_NAME = f\"prediction\"\n","\n","BENCHMARK = 0\n","BAND = 0.2\n","\n","#-----------------------------------------------------\n","\n","# Submissions are scored by spearman correlation\n","def score(df):\n","    # method=\"first\" breaks ties based on order in array\n","    return np.corrcoef(\n","        df[TARGET_NAME],\n","        df[PREDICTION_NAME].rank(pct=True, method=\"first\")\n","    )[0, 1]\n","\n","# The payout function\n","def payout(scores):\n","    return ((scores - BENCHMARK) / BAND).clip(lower=-1, upper=1)\n","\n","\n","# Read the csv file into a pandas Dataframe\n","def read_csv(file_path):\n","    with open(file_path, 'r') as f:\n","        column_names = next(csv.reader(f))\n","        dtypes = {x: np.float16 for x in column_names if\n","                  x.startswith(('feature', 'target'))}\n","    return pd.read_csv(file_path, dtype=dtypes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GDVneQHK5T2B"},"source":["##################################################################\n","#####################   MORE METRICS   ###########################\n","##################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WInhlaAl60of"},"source":["TRAIN_EVAL_PREFIX = \"train\"\n","VAL_EVAL_PREFIX = \"val\"\n","\n","#Some evaluation metrics\n","def ar1(x):\n","    return np.corrcoef(x[:-1], x[1:])[0,1]\n","\n","def autocorr_penalty(x):\n","    n = len(x)\n","    p = ar1(x)\n","    return np.sqrt(1 + 2*np.sum([((n - i)/n)*p**i for i in range(1,n)]))\n","\n","def smart_sharpe(x):\n","    return np.mean(x)/(np.std(x, ddof=1)*autocorr_penalty(x))\n","\n","def numerai_sharpe(x):\n","    return ((np.mean(x) - 0.010415154) / np.std(x)) * np.sqrt(12)\n","\n","def spearmanr(target, pred):\n","    return np.corrcoef(\n","        target,\n","        pred.rank(pct=True, method=\"first\")\n","    )[0, 1]\n","\n","#-----------------------------------------------------\n","def get_baisc_per_era_metrics(df:pd.DataFrame, \n","                        isVal=None, \n","                        fig_name=\"per_era_scores.png\") -> pd.Series:\n","    \n","    prefix=None\n","    scores = pd.Series(dtype=float)\n","\n","    preds_ = df[PREDICTION_NAME]\n","    #Some checks for deciding between training and tournament data\n","    if isVal:\n","        #scores[\"tournament_corr_example_preds\"] = spearmanr(preds_, example_preds[PREDICTION_NAME])\n","        df = df[df.data_type == \"validation\"]\n","        prefix=VAL_EVAL_PREFIX\n","        print(\"predicting on validation...\")\n","    else:\n","        df = df\n","        prefix=TRAIN_EVAL_PREFIX\n","        print(\"predicting on train...\")\n","\n","    #-----------------------------------------------------\n","\n","    #Metric Calculations\n","    print(\"getting per era scores\")\n","    era_scores = df.groupby(\"era\").apply(\n","        lambda x: spearmanr(x[TARGET_NAME], x[PREDICTION_NAME]))\n","    \n","    era_scores.sort_index(inplace=True)\n","    era_scores.plot(kind=\"bar\")\n","    print(\"performance over time\")\n","    plt.pyplot.savefig(f\"{prefix}_{fig_name}\")\n","    plt.pyplot.show()\n","\n","    #-----------------------------------------------------\n","    \n","    scores[f\"{prefix}_mean\"] = preds_.mean()\n","    scores[f\"{prefix}_std_dev\"] = preds_.std()\n","    scores[f\"{prefix}_less_than_half\"] = (preds_<0.5).mean()\n","    scores[f\"{prefix}_less_than_mean\"] = (preds_<preds_.mean()).mean()\n","\n","    scores[f\"{prefix}_autocorrelation\"] = ar1(era_scores)\n","    scores[f\"{prefix}_mean correlation\"] = np.mean(era_scores)\n","    scores[f\"{prefix}_Median Correlation\"] = np.median(era_scores)\n","    scores[f\"{prefix}_Variance\"] = np.var(era_scores)\n","    scores[f\"{prefix}_Std. Dev.\"] = np.std(era_scores)\n","    scores[f\"{prefix}_sharpe\"] = np.mean(era_scores)/np.std(era_scores)\n","    scores[f\"{prefix}_smart sharpe\"] = smart_sharpe(era_scores)\n","    scores[f\"{prefix}_Numerai sharpe\"] = numerai_sharpe(era_scores)\n","\n","    print(scores)\n","    del era_scores\n","    del preds_\n","    gc.collect()\n","    return scores\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a9A4b0HQ60kq"},"source":["def neutralize(df, columns, by, proportion=1.0):\n","    scores = df[columns]\n","    exposures = df[by].values\n","    \n","    # constant column to make sure the series is completely neutral to exposures\n","    exposures = np.hstack((exposures, np.array([np.mean(scores)] * len(exposures)).reshape(-1, 1)))\n","    gc.collect()\n","    scores = scores - proportion * exposures.dot(np.linalg.pinv(exposures).dot(scores))\n","    gc.collect()\n","    return scores / scores.std()\n","\n","def calculate_feature_exposure(df, feature_names) -> list:\n","    exposures = []\n","    for feature_name in feature_names:\n","        exposures.append(spearmanr(df[feature_name], df[PREDICTION_NAME]))\n","        \n","    max_feat_exposure = np.max(np.abs(exposures))\n","    square_sum_feature_exposure = np.sum([e**2 for e in exposures])\n","    feature_exposure = np.std(exposures)\n","\n","    #print(max_feat_exposure, square_sum_feature_exposure)\n","\n","    return [feature_exposure, max_feat_exposure, square_sum_feature_exposure]\n","\n","\n","def get_more_metrics(df, feature_names, isVal=None) -> pd.Series:\n","    \n","    more_metrics = pd.Series(dtype=float)\n","    metric_prefix=None\n","    assert PREDICTION_NAME in df.columns\n","\n","    if isVal is None:\n","        isVal = \"validation\" in df[\"data_type\"].unique() #max CPU times: user 65.1 ms\n","\n","    print(isVal)\n","    if isVal:\n","        df = df[df[\"data_type\"]==\"validation\"]\n","        metric_prefix = VAL_EVAL_PREFIX\n","    else:\n","        metric_prefix = TRAIN_EVAL_PREFIX\n","\n","    assert metric_prefix is not None\n","\n","    #-----------------------------------------------------\n","\n","    #per-era scores\n","    \n","    print(\"predicting per-era scores...\")\n","    scores_per_era = df.groupby(\"era\").apply(\n","        lambda df: spearmanr(df[PREDICTION_NAME], df[TARGET_NAME]))\n","    \n","    more_metrics[f\"{metric_prefix}_var\"] = scores_per_era.std()\n","\n","    #-----------------------------------------------------\n","    \n","    #Neutralize\n","    #This takes a significant amount of memory for calculation\n","    print(df.shape)\n","    print(\"Neutralizing...\")\n","    df[f\"neutral_{PREDICTION_NAME}\"] = neutralize(df, PREDICTION_NAME, feature_names)\n","    feature_neutral_mean = df.groupby(\"era\").apply(\n","        lambda x: spearmanr(x[\"neutral_\"+PREDICTION_NAME].values, x[TARGET_NAME])).mean()\n","\n","    more_metrics[f\"{metric_prefix}_feature_neutral_mean\"] = feature_neutral_mean\n","    gc.collect()\n","\n","    #-----------------------------------------------------\n","    print(\"Calculating Feature Exposure...\")\n","    feature_exposure, max_feat_exposure, square_sum_feature_exposure = calculate_feature_exposure(df, feature_names)\n","\n","    more_metrics[f\"{metric_prefix}_feat_exposure\"] = feature_exposure\n","    more_metrics[f\"{metric_prefix}_max_feat_exposure\"] = max_feat_exposure\n","    more_metrics[f\"{metric_prefix}_square_sum_feature_exposure\"] = square_sum_feature_exposure\n","\n","\n","    #-----------------------------------------------------\n","    print(\"Drawdown...\")\n","    rolling_max = (scores_per_era+1).cumprod().rolling(window=100, min_periods=1).max()\n","    daily_value = (scores_per_era+1).cumprod()\n","    max_drawdown = (rolling_max - daily_value).max()\n","\n","    more_metrics[f\"{metric_prefix}_max_drawdown\"] = max_drawdown\n","\n","    return more_metrics"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wp9Gyg52DL6G"},"source":["def get_all_metrics(model, \n","                    feature_names:list=feature_names, \n","                    fig_name=\"per_era_scores\")->pd.Series:\n","\n","    training_preds = model.predict(training_data[feature_names].values)\n","    training_data[PREDICTION_NAME] = np.array(training_preds).reshape(-1,1)\n","\n","    tournament_preds = model.predict(tournament_data[feature_names].values)\n","    tournament_data[PREDICTION_NAME] = np.array(tournament_preds).reshape(-1,1)\n","\n","    del training_preds\n","    del tournament_preds\n","\n","    print(\"evaluating on training data...\")\n","    tr_per_era_scores = get_baisc_per_era_metrics(training_data, isVal=False, fig_name=fig_name)\n","    tr_more_metrics = get_more_metrics(training_data, feature_names ,isVal=False)\n","    gc.collect()\n","\n","    print(\"evaluating on validation data...\")\n","    val_per_era_scores = get_baisc_per_era_metrics(tournament_data, isVal=True, fig_name=fig_name)\n","    val_more_metrics = get_more_metrics(tournament_data, feature_names ,isVal=True)\n","    gc.collect()\n","\n","    return pd.concat([\n","                      tr_per_era_scores, val_per_era_scores,\n","                      tr_more_metrics, val_more_metrics,\n","                      ])\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p5T0pclBfLlF"},"source":["#############################################################################\n","###########################  CREATING SOME MODELS  ##########################\n","#############################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j0Kl9Ov0BVRH","executionInfo":{"status":"ok","timestamp":1625249943314,"user_tz":-120,"elapsed":208,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"67ea6e99-ee1c-459e-ba8f-61241cb6ff91"},"source":["models = dict()\n","\n","# https://neptune.ai/blog/lightgbm-parameters-guide\n","# https://medium.com/analytics-vidhya/hyperparameters-optimization-for-lightgbm-catboost-and-xgboost-regressors-using-bayesian-6e7c495947a9\n","# https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/sklearn_example.py\n","\n","#https://medium.com/riskified-technology/xgboost-lightgbm-or-catboost-which-boosting-algorithm-should-i-use-e7fda7bb36bc\n","#https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db\n","#https://scikit-learn.org/stable/modules/ensemble.html\n","#https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/\n","\n","#############################################################################################################\n","\n","model_1 = LGBMRegressor()\n","models[\"model_1\"] = model_1\n","\n","#############################################################################################################\n","\n","model_2 = LGBMRegressor(bagging_fraction = 0.94, feature_fraction = 0.10, max_depth = 24, min_child_weight = 24, min_split_gain = 0.08, num_leaves = 100)\n","models[\"model_2\"] = model_2\n","\n","#############################################################################################################\n","\n","model_3 = LGBMRegressor(learning_rate = 0.1, n_estimators = 40)\n","models[\"model_3\"] = model_3\n","\n","#############################################################################################################\n","\n","model_4 = XGBRegressor(max_depth=5, learning_rate=0.01, n_estimators=500, colsample_bytree=0.1, alpha=0.1)\n","models[\"model_4\"] = model_4\n","\n","#############################################################################################################\n","\n","model_5 = XGBRegressor(max_depth=5, learning_rate=0.1, n_estimators=50, colsample_bytree=0.5, alpha=0.1)\n","models[\"model_5\"] = model_5\n","\n","#############################################################################################################\n","\n","model_6 = XGBRegressor(max_depth=5, learning_rate=0.1, n_estimators=50, colsample_bytree=0.5)\n","models[\"model_6\"] = model_6\n","\n","#############################################################################################################\n","\n","model_7 = XGBRegressor(max_depth=5, learning_rate=0.01, n_estimators=2000, colsample_bytree=0.1, alpha=0.1)\n","models[\"model_7\"] = model_7\n","\n","#############################################################################################################\n","\n","model_8 = LGBMRegressor(learning_rate = 0.1 , max_depth = 10, feature_fraction = 0.10, subsample = 0.25, num_leaves = 10)\n","models[\"model_8\"] = model_8\n","\n","#############################################################################################################\n","\n","model_9 = LGBMRegressor(learning_rate = 0.1, max_depth = 10, feature_fraction = 0.20, subsample = 0.50, num_leaves = 25)\n","models[\"model_9\"] = model_9\n","\n","#############################################################################################################\n","\n","model_10 = LGBMRegressor(learning_rate = 0.1, max_depth = 10, feature_fraction = 0.50, subsample = 0.75, num_leaves = 50)\n","models[\"model_10\"] = model_10\n","\n","#############################################################################################################\n","\n","model_11 = LGBMRegressor(learning_rate = 0.1 , max_depth = 10, feature_fraction = 0.10, subsample = 0.25, num_leaves = 75)\n","models[\"model_11\"] = model_11\n","\n","#############################################################################################################\n","\n","model_12 = LGBMRegressor(learning_rate = 0.1, max_depth = 10, feature_fraction = 0.20, subsample = 0.50, num_leaves = 100)\n","models[\"model_12\"] = model_12\n","\n","#############################################################################################################\n","\n","model_13 = LGBMRegressor(learning_rate = 0.1, max_depth = 10, feature_fraction = 0.50, subsample = 0.75, num_leaves = 150)\n","models[\"model_13\"] = model_13\n","\n","#############################################################################################################\n","\n","model_14 = XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1)\n","models[\"model_14\"] = model_14\n","\n","#############################################################################################################\n","\n","del model_1\n","del model_2\n","del model_3\n","del model_4\n","del model_5\n","del model_6\n","del model_7\n","del model_8\n","del model_9\n","del model_10\n","del model_11\n","del model_12\n","del model_13\n","del model_14\n","\n","gc.collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["176"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"roPmIdyl7F3T"},"source":["models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IWW_5irf7X-7"},"source":["#############################################################################\n","####################   TRAINING MORE MODELS   ###############################\n","#############################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_D3jvshpC3hW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625250513856,"user_tz":-120,"elapsed":564469,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"11ff3de8-65fa-440b-8132-3472b947fb81"},"source":["%%time\n","for model_name in models:\n","    print(f\"Fitting {model_name}...\")\n","\n","    if \"keras\" in model_name:\n","        with tf.device('/device:GPU:0'):\n","            models[model_name].fit(training_data[feature_names].values, training_data[TARGET_NAME].values, \n","                batch_size=512, \n","                epochs=50,\n","                validation_data=(validation_data[feature_names].values, validation_data[TARGET_NAME].values),\n","                )\n","    else:\n","      with tf.device('/device:GPU:0'):\n","          models[model_name].fit(training_data[feature_names].values, training_data[TARGET_NAME].values, early_stopping_rounds=10 )\n","\n","    gc.collect()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fitting mlp_1...\n","Fitting mlp_2...\n","Fitting mlp_3...\n","Fitting mlp_4...\n","[18:19:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","Fitting mlp_5...\n","[18:22:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","Fitting mlp_6...\n","[18:25:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","CPU times: user 2h 11min 37s, sys: 4.04 s, total: 2h 11min 41s\n","Wall time: 9min 24s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5VysffFoc43t"},"source":["##############################################################################\n","########################    EVALUATING MODELS    #############################\n","##############################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kOM9QWZ1J7aZ"},"source":["%%time\n","all_model_metrics = dict()\n","for model_name in models:\n","    \n","    print(f\"\\n----{model_name}----\")\n","    model_metrics = get_all_metrics(models[model_name], feature_names, fig_name = f\"{model_name}.png\")\n","    all_model_metrics[model_name] = model_metrics\n","    \n","    gc.collect()\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y8_GL_WXJ7VZ"},"source":["metric_df = pd.DataFrame.from_dict(all_model_metrics)\n","metric_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AAt5POLe2nM9"},"source":["metric_trans = metric_df.T\n","metric_trans[\"val_Numerai sharpe\"] > 1"],"execution_count":null,"outputs":[]}]}