{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ROUND_240_2.ipynb","provenance":[{"file_id":"1CTjOZkyD3x_jt24rScu44BSodPqNywpu","timestamp":1606847483997}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyONA8R3iHGFn47eXvv1cA+6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"yCLw1xJvQZXg"},"source":["https://parmarsuraj99.medium.com/evaluating-financial-machine-learning-models-on-numerai-3562da8fd90\n","\n","\n","https://forum.numer.ai/t/numerai-model-survey-results/1090\n","https://www.kaggle.com/code1110/numerai-tournament\n","https://colab.research.google.com/drive/1-FOJRUeDEhxrixPBnKRAlxbMboiKWjT6\n","https://towardsdatascience.com/modeling-price-with-regularized-linear-model-xgboost-55e59eae4482\n","https://towardsdatascience.com/training-neural-networks-for-price-prediction-with-tensorflow-8aafe0c55198\n","https://parmarsuraj99.medium.com/evaluating-financial-machine-learning-models-on-numerai-3562da8fd90\n","http://www.philipkalinda.com/ds3.html\n","https://www.kaggle.com/rahulharlalka/iris-species-classification-100-accuracy\n","https://colab.research.google.com/github/parmarsuraj99/numerai-guides/blob/master/better_evaluation/Numerai_evaluate_better.ipynb\n","https://medium.com/@parmarsuraj99/evaluating-financial-machine-learning-models-on-numerai-3562da8fd90\n","https://colab.research.google.com/drive/1W4XNv9vwsMLnoKPgWti8JzHrXhE1-YjK#scrollTo=tCdoumbycX_k\n","https://towardsdatascience.com/a-guide-to-the-hardest-data-science-tournament-on-the-planet-748f46e83690\n","https://hackernoon.com/numerai-walkthrough-quantitative-analysis-machine-learning-for-fun-and-profit-3dcdccabd920\n","https://medium.com/@chris_whirlwind/numerai-tutorial-i-vanilla-algorithms-and-adversarial-validation-183b44e98f15\n","https://colab.research.google.com/drive/1un9sQF5063VQ1UH13elYM269ZeYxHKFw?usp=sharing#scrollTo=yGCEWaizehA9\n","https://towardsdatascience.com/a-guide-to-the-hardest-data-science-tournament-on-the-planet-748f46e83690\n","https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/\n","https://github.com/Jeremy123W/Numerai/tree/master/scripts\n","https://machinelearningmastery.com/bagging-ensemble-with-python/\n","https://scikit-learn.org/stable/modules/ensemble.html\n","https://github.com/sarajcev/numerai/blob/master/tsne.py\n","https://github.com/sarajcev/numerai/blob/master/numerai.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-tTyZvlxQaWZ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dXdpJsQ0ZE7G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606333308946,"user_tz":-60,"elapsed":780,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"9df882a0-c0c8-467e-e4e0-b36849e67d1a"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Wed Nov 25 19:41:48 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    26W / 300W |      0MiB / 16130MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RVT42N7PEjp9","executionInfo":{"status":"ok","timestamp":1606415054251,"user_tz":-60,"elapsed":797,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"10c42fd9-85fd-4916-e0ed-f8b2756165c8"},"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n","  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n","  print('re-execute this cell.')\n","else:\n","  print('You are using a high-RAM runtime!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Your runtime has 38.0 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z0_vHKAoAjbU","executionInfo":{"status":"ok","timestamp":1606839854302,"user_tz":-60,"elapsed":5342,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"18970d90-e6ef-4428-9ef0-8eabe8b459ea"},"source":["pip install numerapi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting numerapi\n","  Downloading https://files.pythonhosted.org/packages/81/9d/c583893e96721821560e48aea92dd22aef9fc727151f1efae8f8dc885555/numerapi-2.3.9-py3-none-any.whl\n","Requirement already satisfied: tqdm>=4.29.1 in /usr/local/lib/python3.6/dist-packages (from numerapi) (4.41.1)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from numerapi) (2.8.1)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from numerapi) (2018.9)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from numerapi) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from numerapi) (2.23.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil->numerapi) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->numerapi) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->numerapi) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->numerapi) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->numerapi) (2020.11.8)\n","Installing collected packages: numerapi\n","Successfully installed numerapi-2.3.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M8mAG1KtZJAw"},"source":["'''\n","##################### LIBRARIES ##################################\n","'''\n","import pandas as pd\n","import scipy\n","import numpy as np\n","import numerapi\n","import random\n","import sklearn\n","from sklearn import (\n","    feature_extraction, feature_selection, decomposition, linear_model,\n","    model_selection, metrics, svm, preprocessing, utils\n",")\n","from sklearn.preprocessing import StandardScaler,MinMaxScaler, OrdinalEncoder, LabelEncoder,OneHotEncoder\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from keras.models import Sequential, model_from_json, load_model\n","from keras.layers import Dense, Dropout, Activation,LSTM,Bidirectional, MaxPooling2D, Flatten,GRU\n","from keras.optimizers import SGD,Adam\n","from keras.regularizers import l2\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, GridSearchCV,cross_val_score,KFold, RepeatedStratifiedKFold,train_test_split\n","from sklearn.metrics import log_loss, make_scorer, mean_squared_error,classification_report,accuracy_score\n","from keras.layers.normalization import BatchNormalization\n","from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n","import tensorflow as tf\n","from keras.utils import np_utils \n","from sklearn import preprocessing\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from xgboost import XGBRegressor \n","from sklearn.cluster import KMeans\n","import xgboost as xgb\n","import matplotlib as plt\n","from sklearn.ensemble import RandomForestClassifier as RFC\n","from sklearn.svm import SVC as svc\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.naive_bayes import GaussianNB, BernoulliNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler,MinMaxScaler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cnTok3etZJGl"},"source":["seed = 3\n","rand = np.random.seed(seed)\n","\n","TOURNAMENT_NAME = \"nomi\"\n","TARGET_NAME = f\"target_{TOURNAMENT_NAME}\"\n","PREDICTION_NAME = f\"prediction_{TOURNAMENT_NAME}\"\n","\n","\n","#MODEL_FILE = tf.keras.models.load_model('numeraiMLP338.h5')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NPWbgESZY_tw"},"source":["'''\n","##################### CLASSES AND FUNCTIONS ##################################\n","'''\n","\n","class Download():\n","    \n","    def training(self):\n","        import pandas as pd\n","        df_training = pd.read_csv(\"https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_training_data.csv.xz\")\n","        return df_training\n","    \n","    def tournament(self):\n","        import pandas as pd\n","        df_tournament = pd.read_csv(\"https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_tournament_data.csv.xz\")\n","        return df_tournament\n","    \n","class Submission():\n","\n","    def make_submission(self,df_tournament_data):\n","        \n","        print(\"Generating Public_ID and Model_ID...\")\n","        # Get your API keys and model_id from https://numer.ai/submit\n","        public_id = \"7TISUDGAWEVO2B35ECOQQXU2RWXGZN3I\"\n","        secret_key = \"QJYUWIMFEEDNZ4GHUO6VSSKPMRCBFJIMJ7BZ65ESIWRN4YHGYHSRJDNL64TAG7EH\"\n","        model_id = \"d49c26a4-aa5b-4490-9d58-300c5e05d996\"\n","        napi = numerapi.NumerAPI(public_id=public_id, secret_key=secret_key)\n","        print(\"Generated!\")\n","        \n","        print(\"Generating DataFrame to submission...\")\n","        predictions_df = df_tournament_data[\"id\"].to_frame()\n","        predictions_df[\"prediction\"] = df_tournament_data[PREDICTION_NAME]\n","        print(\"Generated!\")\n","        \n","        print(\"Uploading DataFrame in Numerai...\")\n","        # Upload your predictions\n","        predictions_df.to_csv(\"predictions.csv\", index=False)\n","        submission_id = napi.upload_predictions(\"predictions.csv\", model_id=model_id)\n","        print(\"DataFrame Uploaded...\")\n","        \n","        return predictions_df\n","\n","class Stats():\n","\n","    def statics(df_tournament_data):\n","        \n","        \"\"\"Validation Metrics\"\"\"\n","        # Check the per-era correlations on the validation set (out of sample)\n","        validation_data = df_tournament_data[df_tournament_data.data_type == \"validation\"]\n","        validation_correlations = validation_data.groupby(\"era\").apply(score)\n","        \n","        validation_sharpe = validation_correlations.mean() / validation_correlations.std()\n","        \n","        return validation_sharpe\n","            \n","    def correlation(self,predictions, targets):\n","        ranked_preds = predictions.rank(pct=True, method=\"first\")\n","        return np.corrcoef(ranked_preds, targets)[0, 1]\n","\n","    def score(self,df):\n","        return Stats.correlation(df[PREDICTION_NAME], df[TARGET_NAME])\n","\n","    def payout(self,scores):\n","        return scores.clip(lower=-0.25, upper=0.25)\n","        \n","        \n","def graph_importance(model):\n","    import xgboost as xgb\n","    fig, ax = plt.pyplot.subplots(1,1,figsize=(10,10))\n","    xgb.plot_importance(model, max_num_features=30, ax=ax)\n","\n","def graph_grafo(model):        \n","    xgb.to_graphviz(model, num_trees=1)\n","    \n","def Cluster_Eras(df):\n","\n","    X_clusters_eras = df\n","    eras = [e for e in X_clusters_eras.era.unique()]\n","    X_clusters_eras['eras_cluster'] = X_clusters_eras.era.str.slice(3).astype(int)    \n","    return X_clusters_eras\n","\n","def Cluster_Kmeans(df,X,clusters):\n","    \n","    print('Call algorithm K-means')\n","    kmeans = KMeans(n_clusters=clusters, random_state=rand, init = 'random')\n","    print('Fitting algorithm K-means')\n","    kmeans.fit(X)\n","    print('Finished and Fitted')\n","    X_clusters_kmeans = df\n","    X_clusters_kmeans['k-means'] = kmeans.labels_\n","    return X_clusters_kmeans\n","\n","def KMeans_Clustering_XGBRegressor(df,group,features):\n","    \n","    df_features_X = group[features]\n","    df_features_X['target'] = group.target\n","    X = df_features_X[df_features_X.columns[0:-1]]\n","    Y = df_features_X[df_features_X.columns[-1]]\n","    x_train,x_test,y_train,y_test = train_test_split(X,Y, test_size=0.20,random_state=rand)\n","\n","    model = XGBRegressor(max_depth=5, learning_rate=0.01, n_estimators=2000, colsample_bytree=0.1, verbosity=1, nthread=6)\n","    model.fit(x_train, y_train)\n","\n","    return model, x_train,x_test,y_train,y_test\n","\n","def my_loss_fn(y_true, y_pred):\n","    squared_difference = tf.square(y_true - y_pred)\n","    return tf.reduce_mean(squared_difference, axis=-1)\n","\n","def pearson_cumsom_loss(y_true, y_pred):\n","    '''\n","    optmize negative pearson coefficient loss\n","    :param y_true:\n","    :param y_pred:\n","    :return:\n","    '''\n","    if isinstance(y_true, pd.Series):\n","        y_true = y_true.values\n","    if isinstance(y_pred, pd.Series):\n","        y_pred = y_pred.values\n","    n = len(y_true)\n","    y_bar = y_true.mean()\n","    yhat_bar = y_pred.mean()\n","    c = 1 / ((y_true - y_bar) ** 2).sum().sqrt()  # constant variable\n","    b = ((y_pred - yhat_bar) ** 2).sum().sqrt()  # std of pred\n","\n","    a_i = y_true - y_bar\n","    d_i = y_pred - yhat_bar\n","    a = (a_i * d_i).sum()\n","    gradient = c * (a_i / b - a * d_i / b**3)\n","    hessian = - (np.matmul(a_i.reshape(-1, 1), d_i.reshape(1, -1)) + np.matmul(d_i.reshape(-1, 1), a_i.reshape(1, -1))) / b ** 3 + \\\n","              3 * a * np.matmul(d_i.reshape(-1, 1), d_i.reshape(1, -1)) / b**5 + a/(n*b**3)\n","    hessian = hessian - np.ones(shape=(n, n)) * a/b**3\n","    hessian *= c\n","    return -gradient, -hessian"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"resM2PzCZDoi"},"source":["dw = Download()\n","sub = Submission()\n","st = Stats()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bP3nmA2zZiBh"},"source":["'''\n","##################### BEGIN LOGIC OF THE MODEL ##################################\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cv78NN2SZiYv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606839979616,"user_tz":-60,"elapsed":101173,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"205b0eff-b0b5-49e2-dee6-f33bbcbf0a6d"},"source":["'''\n","##############################################################################\n","########################## DOWLOAD DATA ######################################\n","##############################################################################\n","'''\n","napi = numerapi.NumerAPI(verbosity=\"info\")\n","\n","if napi.check_new_round():\n","    print(\"new round has started within the last 24hours!\")\n","else:\n","    print(\"no new round within the last 24 hours\")\n","\n","print(\"Loading data...\")\n","training_data = dw.training()\n","tournament_data = dw.tournament()\n","print(\"Data downloaded...\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["no new round within the last 24 hours\n","Loading data...\n","Data downloaded...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8O0IyD5yZtv1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606842420072,"user_tz":-60,"elapsed":36283,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"5abd6994-f15a-4cc0-ca3e-639c80cf8a48"},"source":["'''\n","##############################################################################\n","########################  DIVIDE DATA  in X and Y  ###########################\n","##############################################################################\n","'''\n","# model = MODEL_FILE\n","\n","# validation_data = tournament_data[tournament_data.data_type=='validation']\n","# complete_training_data = pd.concat([training_data, validation_data])\n","\n","complete_training_data = training_data\n","feature_cols = training_data.columns[training_data.columns.str.startswith('feature')]\n","print(f\"Loaded {len(feature_cols)} features\")\n","\n","df_features = complete_training_data[feature_cols]\n","df_features[TARGET_NAME] = complete_training_data['target'].values\n","\n","# NORAML DATA\n","\n","X = df_features[df_features.columns[0:-1]]\n","Y = df_features[df_features.columns[-1]]\n","\n","# ENCODER Y 2 TYPES\n","\n","le = LabelEncoder()\n","Y_enc = le.fit_transform(Y)\n","dummy_y = np_utils.to_categorical(Y_enc)\n","df_dummy_y = pd.DataFrame(dummy_y)\n","\n","# PCA WITHOUT SCALER\n","\n","pca2 = PCA(n_components=125, random_state=rand)\n","pca_2 = pca2.fit_transform(training_data[feature_cols])\n","df_zero = pd.DataFrame(pca_2, columns=[feature_cols[0:125]])\n","X_zero = df_zero\n","\n","# SCALED DATA\n","\n","df_x = training_data[feature_cols]\n","ss = StandardScaler()\n","df_x[feature_cols] = ss.fit_transform(df_x[feature_cols])\n","X_x = df_x\n","\n","# PCA WITH SCALED DATA\n","\n","df_z = df_x\n","pca2 = PCA(n_components=125, random_state=rand)\n","pca_2 = pca2.fit_transform(df_z)\n","df_z = pd.DataFrame(pca_2, columns=[feature_cols[0:125]])\n","X_z = df_z"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loaded 310 features\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  app.launch_new_instance()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3076: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self.iloc._setitem_with_indexer((slice(None), indexer), value)\n","/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3041: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_array(key, value)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"MveXDE9dGaFG"},"source":["'''\n","##################### BEGINNING OF THE MODEL ##################################\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hGaPlBjZBTa7"},"source":["'''\n","##############################################################################\n","###########################  MODEL ONE  ######################################\n","##############################################################################\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pekipdenMvZJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606843083698,"user_tz":-60,"elapsed":628142,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"523ee240-ab34-455e-a4f3-437974f57d49"},"source":["print('Call algorithm K-means')\n","kmeans = KMeans(n_clusters=10, random_state=rand, init = 'random')\n","print('Fitting algorithm K-means')\n","kmeans.fit(X)\n","print('Finished and Fitted')\n","X_clusters_kmeans = training_data\n","X_clusters_kmeans['k-means'] = kmeans.labels_"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Call algorithm K-means\n","Fitting algorithm K-means\n","Finished and Fitted\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1oqtsAJiaD9j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606843471058,"user_tz":-60,"elapsed":4928,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"c8b2f7b2-f2dc-4386-c222-7c7a14cd08f5"},"source":["X_group_1 = X_clusters_kmeans.loc[X_clusters_kmeans['k-means'] == 0]\n","X_group_2 = X_clusters_kmeans.loc[X_clusters_kmeans['k-means'] == 1]\n","X_group_3 = X_clusters_kmeans.loc[X_clusters_kmeans['k-means'] == 2]\n","X_group_4 = X_clusters_kmeans.loc[X_clusters_kmeans['k-means'] == 3]\n","X_group_5 = X_clusters_kmeans.loc[X_clusters_kmeans['k-means'] == 4]\n","X_group_6 = X_clusters_kmeans.loc[X_clusters_kmeans['k-means'] == 5]\n","X_group_7 = X_clusters_kmeans.loc[X_clusters_kmeans['k-means'] == 6]\n","X_group_8 = X_clusters_kmeans.loc[X_clusters_kmeans['k-means'] == 7]\n","X_group_9 = X_clusters_kmeans.loc[X_clusters_kmeans['k-means'] == 8]\n","X_group_10 = X_clusters_kmeans.loc[X_clusters_kmeans['k-means'] == 9]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-12-01 17:24:26,378 INFO numexpr.utils: Note: NumExpr detected 40 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n","2020-12-01 17:24:26,379 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xX_cuJkbXCTp"},"source":["########################## SEGMENTATION OF DATA  ##############################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hKhLDs0SMraG"},"source":["x_train,x_test,y_train,y_test = train_test_split(X,Y, test_size=0.20,random_state=rand)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWAPYgtmqjiN"},"source":["########################## MODEL KERAS ######################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qa5-6y3JVrB6"},"source":["def Grouping_Models(df_train):\n","    x_train,x_test,y_train,y_test = train_test_split(X,Y, test_size=0.20,random_state=rand)\n","    input_data = tf.keras.Input(shape=(len(feature_cols),))\n","    # tf.keras.layers.PReLU(alpha_initializer=\"zeros\", alpha_regularizer=None, alpha_constraint=None, shared_axes=None)\n","    # tf.keras.layers.ELU(alpha=1.0)\n","    # tf.keras.layers.ThresholdedReLU(theta=1.0)\n","    # tf.keras.layers.LeakyReLU(alpha=0.3)\n","    layer = tf.keras.layers.LeakyReLU(alpha=0.1)\n","    final_layer = tf.keras.layers.Softmax(axis=-1)\n","    x = tf.keras.layers.Dense(len(feature_cols), activation=layer)(input_data)\n","    x = tf.keras.layers.Dense(len(feature_cols) // 2, activation=layer)(x)\n","    x = tf.keras.layers.Dense(len(feature_cols) // 4, activation=layer)(x)\n","    output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n","    optimizer = tf.keras.optimizers.Adam( learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\n","    model = tf.keras.Model(input_data, output)\n","    # model.compile(optimizer=optimizer, loss=pearson_cumsom_loss, metrics=['mae', 'mse'])\n","    epochs=50\n","    batch_size = len(training_data) // 1000 * 3\n","    model.compile(optimizer=optimizer, loss=my_loss_fn, metrics=['mae', 'mse'])\n","    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, shuffle=True, validation_data=(x_test, y_test))\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yYS_08KbVgy2"},"source":["model_group_1 = Grouping_Models(X_group_1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"febfiuHxqjkH"},"source":["\n","input_data = tf.keras.Input(shape=(len(feature_cols),))\n","\n","# tf.keras.layers.PReLU(alpha_initializer=\"zeros\", alpha_regularizer=None, alpha_constraint=None, shared_axes=None)\n","# tf.keras.layers.ELU(alpha=1.0)\n","# tf.keras.layers.ThresholdedReLU(theta=1.0)\n","# tf.keras.layers.LeakyReLU(alpha=0.3)\n","layer = tf.keras.layers.LeakyReLU(alpha=0.1)\n","\n","final_layer = tf.keras.layers.Softmax(axis=-1)\n","\n","x = tf.keras.layers.Dense(len(feature_cols), activation=layer)(input_data)\n","x = tf.keras.layers.Dense(len(feature_cols) // 2, activation=layer)(x)\n","x = tf.keras.layers.Dense(len(feature_cols) // 4, activation=layer)(x)\n","\n","output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n","\n","optimizer = tf.keras.optimizers.Adam( learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\n","\n","model = tf.keras.Model(input_data, output)\n","\n","# model.compile(optimizer=optimizer, loss=pearson_cumsom_loss, metrics=['mae', 'mse'])\n","model.compile(optimizer=optimizer, loss=my_loss_fn, metrics=['mae', 'mse'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eQDiljexqjlm"},"source":["epochs=50\n","batch_size = len(training_data) // 1000 * 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dd79ZbdRqjny"},"source":["model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, shuffle=True, validation_data=(x_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5xJY_2ySqppr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606726053700,"user_tz":-60,"elapsed":7169,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"ae488c56-2fe0-45ce-a895-b06876429927"},"source":["third_prediction = model.predict(x_test)\n","third_prediction = pd.DataFrame(third_prediction)\n","third_prediction\n","\n","scores = model.evaluate(x_test, y_test, verbose=1)\n","\n","print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3137/3137 [==============================] - 3s 982us/step - loss: 0.0579 - mae: 0.1724 - mse: 0.0579\n","\n","mae: 17.24%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"id":"2uRk1OjOpq-5","executionInfo":{"status":"ok","timestamp":1606726063835,"user_tz":-60,"elapsed":1028,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"3381a435-0084-4d9f-9389-590e54333b07"},"source":["third_prediction"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.501387</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.444317</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.243119</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.513014</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.748194</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>100357</th>\n","      <td>0.509490</td>\n","    </tr>\n","    <tr>\n","      <th>100358</th>\n","      <td>0.506129</td>\n","    </tr>\n","    <tr>\n","      <th>100359</th>\n","      <td>0.408933</td>\n","    </tr>\n","    <tr>\n","      <th>100360</th>\n","      <td>0.496940</td>\n","    </tr>\n","    <tr>\n","      <th>100361</th>\n","      <td>0.311762</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100362 rows Ã— 1 columns</p>\n","</div>"],"text/plain":["               0\n","0       0.501387\n","1       0.444317\n","2       0.243119\n","3       0.513014\n","4       0.748194\n","...          ...\n","100357  0.509490\n","100358  0.506129\n","100359  0.408933\n","100360  0.496940\n","100361  0.311762\n","\n","[100362 rows x 1 columns]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"NtM_9RHLtx3E"},"source":["tf.keras.utils.plot_model(model, 'model.png', show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6vWrkGkrO5l7"},"source":["labels_tournament = kmeans.predict(tournament_data[feature_cols])\n","tournament_data['k-means'] = labels_tournament"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2ZgO0nmPxEY"},"source":["X_group_1_td = tournament_data.loc[tournament_data['k-means'] == 0]\n","X_group_2_td = tournament_data.loc[tournament_data['k-means'] == 1]\n","X_group_3_td = tournament_data.loc[tournament_data['k-means'] == 2]\n","X_group_4_td = tournament_data.loc[tournament_data['k-means'] == 3]\n","X_group_5_td = tournament_data.loc[tournament_data['k-means'] == 4]\n","X_group_6_td = tournament_data.loc[tournament_data['k-means'] == 5]\n","X_group_7_td = tournament_data.loc[tournament_data['k-means'] == 6]\n","X_group_8_td = tournament_data.loc[tournament_data['k-means'] == 7]\n","X_group_9_td = tournament_data.loc[tournament_data['k-means'] == 8]\n","X_group_10_td = tournament_data.loc[tournament_data['k-means'] == 9]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aFUNoQ_2VvFw"},"source":["prediction_group_1 = X_group_1_td['id'].to_frame()\n","prediction_group_1[\"prediction\"] = model_group_1.predict(X_group_1_td[feature_cols])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wIriQ4C4Xi6P"},"source":["prediction_group_2 = X_group_2_td['id'].to_frame()\n","prediction_group_2[\"prediction\"] = model_group_2.predict(X_group_2_td[feature_cols])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bou7bxkJXjD9"},"source":["prediction_group_3 = X_group_3_td['id'].to_frame()\n","prediction_group_3[\"prediction\"] = model_group_3.predict(X_group_3_td[feature_cols])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i4EuijrlXjNG"},"source":["prediction_group_4 = X_group_4_td['id'].to_frame()\n","prediction_group_4[\"prediction\"] = model_group_4.predict(X_group_4_td[feature_cols])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_pkHQ2XhXjWc"},"source":["prediction_group_5 = X_group_5_td['id'].to_frame()\n","prediction_group_5[\"prediction\"] = model_group_5.predict(X_group_5_td[feature_cols])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iS_phiaRHAKr"},"source":["prediction_group_6 = X_group_6_td['id'].to_frame()\n","prediction_group_6[\"prediction\"] = model_group_6.predict(X_group_6_td[feature_cols])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fZzSrXqeHAhf"},"source":["prediction_group_7 = X_group_7_td['id'].to_frame()\n","prediction_group_7[\"prediction\"] = model_group_7.predict(X_group_7_td[feature_cols])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wgSbA3YUHA1a"},"source":["prediction_group_8 = X_group_8_td['id'].to_frame()\n","prediction_group_8[\"prediction\"] = model_group_8.predict(X_group_8_td[feature_cols])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5olUxFYEHBJk"},"source":["prediction_group_9 = X_group_9_td['id'].to_frame()\n","prediction_group_9[\"prediction\"] = model_group_9.predict(X_group_9_td[feature_cols])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V_UaKCqKHBgC"},"source":["prediction_group_10 = X_group_10_td['id'].to_frame()\n","prediction_group_10[\"prediction\"] = model_group_10.predict(X_group_10_td[feature_cols])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"leSzJugXBThA"},"source":["'''\n","##############################################################################\n","###########################  MODEL TWO  ######################################\n","##############################################################################\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hjf2PARiBTq5"},"source":["import numerapi\n","import torch\n","from torch.nn import Linear\n","from torch.nn import Sequential\n","from torch.functional import F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3eMog4NVF4d_"},"source":["def exposures(x, y):\n","    x = x - x.mean(dim=0)\n","    x = x / x.norm(dim=0)\n","    y = y - y.mean(dim=0)\n","    y = y / y.norm(dim=0)\n","    return torch.matmul(x.T, y)\n","\n","def reduce_exposure(prediction, features, max_exp):\n","    # linear model of features that will be used to partially neutralize predictions\n","    lin = Linear(features.shape[1],  1, bias=False)\n","    lin.weight.data.fill_(0.)\n","    model = Sequential(lin)\n","    optimizer = torch.optim.Adamax(model.parameters(), lr=1e-4)\n","    feats = torch.tensor(np.float32(features)-.5)\n","    pred = torch.tensor(np.float32(prediction))\n","    start_exp = exposures(feats, pred[:,None])\n","    # set target exposure for each feature to be <= current exposure\n","    # if current exposure is less than max_exp, or <= max_exp if  \n","    # current exposure is > max_exp\n","    targ_exp = torch.clamp(start_exp, -max_exp, max_exp)\n","\n","    for i in range(100):\n","        optimizer.zero_grad()\n","        # calculate feature exposures of current linear neutralization\n","        exps = exposures(feats, pred[:,None]-model(feats))\n","        # loss is positive when any exposures exceed their target\n","        loss = (F.relu(F.relu(exps)-F.relu(targ_exp)) + F.relu(F.relu(-exps)-F.relu(-targ_exp))).sum()\n","        print(f'       loss: {loss:0.7f}', end='\\r')\n","        if loss < 1e-7:\n","            neutralizer = [p.detach().numpy() for p in model.parameters()]\n","            neutralized_pred = pred[:,None]-model(feats)\n","            break\n","        loss.backward()\n","        optimizer.step()\n","    return neutralized_pred, neutralizer\n","\n","def exposures(x, y):\n","    x = x - x.mean(dim=0)\n","    x = x / x.norm(dim=0)\n","    y = y - y.mean(dim=0)\n","    y = y / y.norm(dim=0)\n","    return torch.matmul(x.T, y)\n","\n","def reduce_exposure(prediction, features, max_exp):\n","    # linear model of features that will be used to partially neutralize predictions\n","    lin = Linear(features.shape[1],  1, bias=False)\n","    lin.weight.data.fill_(0.)\n","    model = Sequential(lin)\n","    optimizer = torch.optim.Adamax(model.parameters(), lr=1e-4)\n","    feats = torch.tensor(np.float32(features)-.5)\n","    pred = torch.tensor(np.float32(prediction))\n","    start_exp = exposures(feats, pred[:,None])\n","    # set target exposure for each feature to be <= current exposure\n","    # if current exposure is less than max_exp, or <= max_exp if  \n","    # current exposure is > max_exp\n","    targ_exp = torch.clamp(start_exp, -max_exp, max_exp)\n","\n","    for i in range(100000):\n","        optimizer.zero_grad()\n","        # calculate feature exposures of current linear neutralization\n","        exps = exposures(feats, pred[:,None]-model(feats))\n","        # loss is positive when any exposures exceed their target\n","        loss = (F.relu(F.relu(exps)-F.relu(targ_exp)) + F.relu(F.relu(-exps)-F.relu(-targ_exp))).sum()\n","        print(f'       loss: {loss:0.7f}', end='\\r')\n","        if loss < 1e-7:\n","            neutralizer = [p.detach().numpy() for p in model.parameters()]\n","            neutralized_pred = pred[:,None]-model(feats)\n","            break\n","        loss.backward()\n","        optimizer.step()\n","    return neutralized_pred, neutralizer\n","\n","def reduce_all_exposures(df, column, neutralizers=[],\n","                                     normalize=True,\n","                                     gaussianize=True,\n","                                     era_col=\"era\",\n","                                     max_exp=0.1):\n","    unique_eras = df[era_col].unique()\n","    computed = []\n","    for u in unique_eras:\n","        print(u, '\\r')\n","        df_era = df[df[era_col] == u]\n","        scores = df_era[column].values\n","        exposure_values = df_era[neutralizers].values\n","        \n","        if normalize:\n","            scores2 = []\n","            for x in scores.T:\n","                x = (scipy.stats.rankdata(x, method='ordinal') - .5) / len(x)\n","                if gaussianize:\n","                    x = scipy.stats.norm.ppf(x)\n","                scores2.append(x)\n","            scores = np.array(scores2)[0]\n","\n","        scores, neut = reduce_exposure(scores, exposure_values, max_exp)\n","\n","        scores /= scores.std()\n","\n","        computed.append(scores.detach().numpy())\n","\n","    return pd.DataFrame(np.concatenate(computed), columns=column, index=df.index)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-XenZQRvF7R1"},"source":["tournament_data[PREDICTION_NAME] = model.predict(tournament_data[feature_cols])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qK0-KsknhDEJ"},"source":["tournament_data[PREDICTION_NAME]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n4nMrFmM3edZ"},"source":["data_rfe_10 = reduce_all_exposures(tournament_data,\n","                                   [PREDICTION_NAME],\n","                                   neutralizers=feature_cols,\n","                                   era_col=\"era\",\n","                                   max_exp=0.10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RObC2NoGF-p1"},"source":["# replace prediction with reduced feature exposure prediction and rescale to [0,1]\n","tournament_data[PREDICTION_NAME] = data_rfe_10[PREDICTION_NAME]\n","tournament_data[PREDICTION_NAME] -= tournament_data[PREDICTION_NAME].min()\n","tournament_data[PREDICTION_NAME] /= tournament_data[PREDICTION_NAME].max()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qJIpIboDlF0N"},"source":["tournament_data[PREDICTION_NAME]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ck1atloUZt-M"},"source":["'''\n","##############################################################################\n","######################## MAKE PREDICTIONS ####################################\n","##############################################################################\n","'''\n","print(\"Generating predictions...\")\n","    \n","torunament_features = tournament_data[feature_cols]\n","enc_Y_tournament = model.predict(torunament_features)\n","df_enc_Y_tournament = pd.DataFrame(enc_Y_tournament)\n","tournament_data[PREDICTION_NAME] = df_enc_Y_tournament\n","\n","print(\"Predictions Generated...\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKoPUjxmZie4"},"source":["'''\n","##############################################################################\n","############################  STATICS  #######################################\n","##############################################################################\n","'''\n","value  = st.statics(tournament_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XRj2Fv22druq"},"source":["'''\n","##############################################################################\n","######################### MAKE SUBMISSION #################################### \n","##############################################################################\n","'''\n","\n","print(\"Generating Public_ID and Model_ID...\")\n","# Get your API keys and model_id from https://numer.ai/submit\n","public_id = \"7TISUDGAWEVO2B35ECOQQXU2RWXGZN3I\"\n","secret_key = \"QJYUWIMFEEDNZ4GHUO6VSSKPMRCBFJIMJ7BZ65ESIWRN4YHGYHSRJDNL64TAG7EH\"\n","model_id = \"d49c26a4-aa5b-4490-9d58-300c5e05d996\"\n","napi = numerapi.NumerAPI(public_id=public_id, secret_key=secret_key)\n","print(\"Generated!\")\n","\n","print(\"Generating DataFrame to submission...\")\n","predictions_df = tournament_data[\"id\"].to_frame()\n","predictions_df[\"prediction\"] = tournament_data[PREDICTION_NAME]\n","print(\"Generated!\")\n","\n","print(\"Uploading DataFrame in Numerai...\")\n","# Upload your predictions\n","predictions_df.to_csv(\"predictions.csv\", index=False)\n","submission_id = napi.upload_predictions(\"predictions.csv\", model_id=model_id)\n","print(\"DataFrame Uploaded...\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z6QoTaBWdbhi"},"source":["'''\n","##############################################################################\n","########################  SAVE AND LOAD THE MODEL  ###########################\n","##############################################################################\n","'''\n","# SAVE MODEL\n","model.save_weights('numeraiThe_Model.h5', overwrite=True, save_format=None, options=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GK06Dckulvmw"},"source":["# LOAD MODEL\n","model.load_weights('numeraiThe_Model.h5', by_name=False, skip_mismatch=False, options=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kgD9euA0mt9H"},"source":[""],"execution_count":null,"outputs":[]}]}