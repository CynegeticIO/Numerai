{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"The_Model_2.ipynb","provenance":[{"file_id":"https://github.com/parmarsuraj99/numerai-guides/blob/master/better_evaluation/Numerai_evaluate_better.ipynb","timestamp":1606918739349}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"GjYh7u4jsWul"},"source":["Created by Joan-Marc Fisa\n","\n","- Numerai: [FisaGol](https://numer.ai/fisagol)\n","\n","- Twitter: [@fisagol](https://twitter.com/fisagol)\n"]},{"cell_type":"markdown","metadata":{"id":"esSvK3mcccGn"},"source":["# Evaluating Financial Machine Learning Models on Numerai"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YWzJuCgodiHc","executionInfo":{"elapsed":957,"status":"ok","timestamp":1606929493919,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"},"user_tz":-60},"outputId":"8b09edc7-6b5b-4d69-bda5-004bb7846698"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, \n","and then re-execute this cell.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Xu_6z9kdkFv","executionInfo":{"elapsed":1220,"status":"ok","timestamp":1606929511124,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"},"user_tz":-60},"outputId":"6956a1c7-141d-4647-d912-f3ff4bcc5bf8"},"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n","  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n","  print('re-execute this cell.')\n","else:\n","  print('You are using a high-RAM runtime!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Your runtime has 38.0 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dukzbOx5YPL2","executionInfo":{"elapsed":13647,"status":"ok","timestamp":1607169732298,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"},"user_tz":-60},"outputId":"7876abf0-35c6-46a7-d9b9-3115b41a8737"},"source":["!pip install numerapi\n","!pip install catboost;"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting numerapi\n","  Downloading https://files.pythonhosted.org/packages/81/9d/c583893e96721821560e48aea92dd22aef9fc727151f1efae8f8dc885555/numerapi-2.3.9-py3-none-any.whl\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from numerapi) (2.8.1)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from numerapi) (7.1.2)\n","Requirement already satisfied: tqdm>=4.29.1 in /usr/local/lib/python3.6/dist-packages (from numerapi) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from numerapi) (2.23.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from numerapi) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil->numerapi) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->numerapi) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->numerapi) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->numerapi) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->numerapi) (2020.11.8)\n","Installing collected packages: numerapi\n","Successfully installed numerapi-2.3.9\n","Collecting catboost\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/c1/c1c4707013f9e2f8a96899dd3a87f66c9167d6d776a6dc8fe7ec8678d446/catboost-0.24.3-cp36-none-manylinux1_x86_64.whl (66.3MB)\n","\u001b[K     |████████████████████████████████| 66.3MB 104kB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n","Installing collected packages: catboost\n","Successfully installed catboost-0.24.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S-llL1U4drNA"},"source":["##################################################################\n","##################### LIBRARIES ##################################\n","##################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L3qA9k0VZ4Hj"},"source":["import os\n","import gc\n","import csv\n","import sys\n","import glob\n","import time\n","from pathlib import Path\n","from multiprocessing import Pool\n","\n","import numerapi\n","\n","import scipy\n","import numpy as np\n","import pandas as pd\n","#import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from catboost import CatBoostRegressor\n","from sklearn.linear_model import LinearRegression\n","\n","import random\n","import sklearn\n","from sklearn import (\n","    feature_extraction, feature_selection, decomposition, linear_model,\n","    model_selection, metrics, svm, preprocessing, utils\n",")\n","from sklearn.preprocessing import StandardScaler,MinMaxScaler, OrdinalEncoder, LabelEncoder,OneHotEncoder\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from keras.models import Sequential, model_from_json, load_model\n","from keras.layers import Dense, Dropout, Activation,LSTM,Bidirectional, MaxPooling2D, Flatten,GRU\n","from keras.optimizers import SGD,Adam\n","from keras.regularizers import l2\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, GridSearchCV,cross_val_score,KFold, RepeatedStratifiedKFold,train_test_split\n","from sklearn.metrics import log_loss, make_scorer, mean_squared_error,classification_report,accuracy_score\n","from keras.layers.normalization import BatchNormalization\n","from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n","import tensorflow as tf\n","from keras.utils import np_utils \n","from sklearn import preprocessing\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from xgboost import XGBRegressor \n","from sklearn.cluster import KMeans\n","import xgboost as xgb\n","import matplotlib as plt\n","from sklearn.ensemble import RandomForestClassifier as RFC\n","from sklearn.svm import SVC as svc\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.naive_bayes import GaussianNB, BernoulliNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler,MinMaxScaler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"txeNarfXETid"},"source":["'''\n","##################### CLASSES AND FUNCTIONS ##################################\n","'''\n","\n","class Download():\n","    \n","    def training(self):\n","        import pandas as pd\n","        df_training = pd.read_csv(\"https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_training_data.csv.xz\")\n","        return df_training\n","    \n","    def tournament(self):\n","        import pandas as pd\n","        df_tournament = pd.read_csv(\"https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_tournament_data.csv.xz\")\n","        return df_tournament\n","    \n","class Submission():\n","\n","    def make_submission(self,df_tournament_data):\n","        \n","        print(\"Generating Public_ID and Model_ID...\")\n","        # Get your API keys and model_id from https://numer.ai/submit\n","        public_id = \"7TISUDGAWEVO2B35ECOQQXU2RWXGZN3I\"\n","        secret_key = \"QJYUWIMFEEDNZ4GHUO6VSSKPMRCBFJIMJ7BZ65ESIWRN4YHGYHSRJDNL64TAG7EH\"\n","        model_id = \"d49c26a4-aa5b-4490-9d58-300c5e05d996\"\n","        napi = numerapi.NumerAPI(public_id=public_id, secret_key=secret_key)\n","        print(\"Generated!\")\n","        \n","        print(\"Generating DataFrame to submission...\")\n","        predictions_df = df_tournament_data[\"id\"].to_frame()\n","        predictions_df[\"prediction\"] = df_tournament_data[PREDICTION_NAME]\n","        print(\"Generated!\")\n","        \n","        print(\"Uploading DataFrame in Numerai...\")\n","        # Upload your predictions\n","        predictions_df.to_csv(\"predictions.csv\", index=False)\n","        submission_id = napi.upload_predictions(\"predictions.csv\", model_id=model_id)\n","        print(\"DataFrame Uploaded...\")\n","        \n","        return predictions_df\n","\n","class Stats():\n","\n","    def statics(df_tournament_data):\n","        \n","        \"\"\"Validation Metrics\"\"\"\n","        # Check the per-era correlations on the validation set (out of sample)\n","        validation_data = df_tournament_data[df_tournament_data.data_type == \"validation\"]\n","        validation_correlations = validation_data.groupby(\"era\").apply(score)\n","        \n","        validation_sharpe = validation_correlations.mean() / validation_correlations.std()\n","        \n","        return validation_sharpe\n","            \n","    def correlation(self,predictions, targets):\n","        ranked_preds = predictions.rank(pct=True, method=\"first\")\n","        return np.corrcoef(ranked_preds, targets)[0, 1]\n","\n","    def score(self,df):\n","        return Stats.correlation(df[PREDICTION_NAME], df[TARGET_NAME])\n","\n","    def payout(self,scores):\n","        return scores.clip(lower=-0.25, upper=0.25)\n","        \n","        \n","def graph_importance(model):\n","    import xgboost as xgb\n","    fig, ax = plt.pyplot.subplots(1,1,figsize=(10,10))\n","    xgb.plot_importance(model, max_num_features=30, ax=ax)\n","\n","def graph_grafo(model):        \n","    xgb.to_graphviz(model, num_trees=1)\n","    \n","def Cluster_Eras(df):\n","\n","    X_clusters_eras = df\n","    eras = [e for e in X_clusters_eras.era.unique()]\n","    X_clusters_eras['eras_cluster'] = X_clusters_eras.era.str.slice(3).astype(int)    \n","    return X_clusters_eras\n","\n","def Cluster_Kmeans(df,X,clusters):\n","    \n","    print('Call algorithm K-means')\n","    kmeans = KMeans(n_clusters=clusters, random_state=rand, init = 'random')\n","    print('Fitting algorithm K-means')\n","    kmeans.fit(X)\n","    print('Finished and Fitted')\n","    X_clusters_kmeans = df\n","    X_clusters_kmeans['k-means'] = kmeans.labels_\n","    return X_clusters_kmeans\n","\n","def KMeans_Clustering_XGBRegressor(df,group,features):\n","    \n","    df_features_X = group[features]\n","    df_features_X['target'] = group.target\n","    X = df_features_X[df_features_X.columns[0:-1]]\n","    Y = df_features_X[df_features_X.columns[-1]]\n","    x_train,x_test,y_train,y_test = train_test_split(X,Y, test_size=0.20,random_state=rand)\n","\n","    model = XGBRegressor(max_depth=5, learning_rate=0.01, n_estimators=2000, colsample_bytree=0.1, verbosity=1, nthread=6)\n","    model.fit(x_train, y_train)\n","\n","    return model, x_train,x_test,y_train,y_test\n","\n","def my_loss_fn(y_true, y_pred):\n","    squared_difference = tf.square(y_true - y_pred)\n","    return tf.reduce_mean(squared_difference, axis=-1)\n","\n","def pearson_cumsom_loss(y_true, y_pred):\n","  \n","    if isinstance(y_true, pd.Series):\n","        y_true = y_true.values\n","    if isinstance(y_pred, pd.Series):\n","        y_pred = y_pred.values\n","    n = len(y_true)\n","    y_bar = y_true.mean()\n","    yhat_bar = y_pred.mean()\n","    c = 1 / ((y_true - y_bar) ** 2).sum().sqrt()  # constant variable\n","    b = ((y_pred - yhat_bar) ** 2).sum().sqrt()  # std of pred\n","\n","    a_i = y_true - y_bar\n","    d_i = y_pred - yhat_bar\n","    a = (a_i * d_i).sum()\n","    gradient = c * (a_i / b - a * d_i / b**3)\n","    hessian = - (np.matmul(a_i.reshape(-1, 1), d_i.reshape(1, -1)) + np.matmul(d_i.reshape(-1, 1), a_i.reshape(1, -1))) / b ** 3 + \\\n","              3 * a * np.matmul(d_i.reshape(-1, 1), d_i.reshape(1, -1)) / b**5 + a/(n*b**3)\n","    hessian = hessian - np.ones(shape=(n, n)) * a/b**3\n","    hessian *= c\n","    return -gradient, -hessian\n","\n","dw = Download()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CmGYfuWdElvN"},"source":["##############################################################################\n","########################## DOWLOAD DATA ######################################\n","##############################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HPqlpE4-d0G0"},"source":["seed = 3\n","rand = np.random.seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HrzPVfR6egjj","executionInfo":{"elapsed":27086,"status":"ok","timestamp":1607169811568,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"},"user_tz":-60},"outputId":"4293d25d-f1e0-436d-b045-de7b31b6dcf6"},"source":["napi = numerapi.NumerAPI(verbosity=\"info\")\n","\n","napi.download_current_dataset(unzip=True)\n","\n","current_ds = napi.get_current_round()\n","latest_round = os.path.join('numerai_dataset_'+str(current_ds))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["./numerai_dataset_240.zip: 381MB [00:08, 46.3MB/s]                           \n","2020-12-05 12:03:13,730 INFO numerapi.base_api: unzipping file...\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"tHATa1jEq01J"},"source":["TOURNAMENT_NAME = \"nomi\"\n","TARGET_NAME = f\"target\"\n","PREDICTION_NAME = f\"prediction\"\n","\n","BENCHMARK = 0\n","BAND = 0.2\n","\n","#-----------------------------------------------------\n","\n","# Submissions are scored by spearman correlation\n","def score(df):\n","    # method=\"first\" breaks ties based on order in array\n","    return np.corrcoef(\n","        df[TARGET_NAME],\n","        df[PREDICTION_NAME].rank(pct=True, method=\"first\")\n","    )[0, 1]\n","\n","# The payout function\n","def payout(scores):\n","    return ((scores - BENCHMARK) / BAND).clip(lower=-1, upper=1)\n","\n","\n","# Read the csv file into a pandas Dataframe\n","def read_csv(file_path):\n","    with open(file_path, 'r') as f:\n","        column_names = next(csv.reader(f))\n","        dtypes = {x: np.float16 for x in column_names if\n","                  x.startswith(('feature', 'target'))}\n","    return pd.read_csv(file_path, dtype=dtypes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"taUitEnG4UXe"},"source":["##################################################################\n","##################### LOAD DATA ##################################\n","##################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VgodzImqq7z3","executionInfo":{"elapsed":59123,"status":"ok","timestamp":1607169882265,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"},"user_tz":-60},"outputId":"b4058380-641e-40ae-d973-c4dd92444ed9"},"source":["%%time\n","print(\"# Loading data...\")\n","\n","training_data = read_csv(os.path.join(latest_round, \"numerai_training_data.csv\")).set_index(\"id\")\n","tournament_data = read_csv(os.path.join(latest_round, \"numerai_tournament_data.csv\")).set_index(\"id\")\n","validation_data = tournament_data[tournament_data.data_type == \"validation\"]\n","\n","print(\"# All Loaded...\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["# Loading data...\n","# All Loaded...\n","CPU times: user 55.6 s, sys: 2.65 s, total: 58.2 s\n","Wall time: 58.2 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gKGYq1Ce7MHX","executionInfo":{"elapsed":478,"status":"ok","timestamp":1607169968386,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"},"user_tz":-60},"outputId":"87241bef-857f-43a3-ce30-f655bc740428"},"source":["feature_names = [f for f in training_data.columns if f.startswith(\"feature\")]\n","print(f\"Loaded {len(feature_names)} features\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loaded 310 features\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nWLPUTla61YQ"},"source":["TRAIN_EVAL_PREFIX = \"train\"\n","VAL_EVAL_PREFIX = \"val\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6VvQPMGnAUom"},"source":["##############################################################################\n","########################  DIVIDE DATA  in X and Y  ###########################\n","##############################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fny3h85kAb2H"},"source":["# NORAML DATA\n","\n","X = training_data[training_data.columns[3:-1]]\n","Y = training_data[training_data.columns[-1]]\n","\n","# ENCODER Y 2 TYPES\n","\n","le = LabelEncoder()\n","Y_enc = le.fit_transform(Y)\n","dummy_y = np_utils.to_categorical(Y_enc)\n","df_dummy_y = pd.DataFrame(dummy_y)\n","\n","#PCA WITHOUT SCALER\n","\n","pca2 = PCA(n_components=125, random_state=rand)\n","pca_2 = pca2.fit_transform(training_data[feature_cols])\n","df_zero = pd.DataFrame(pca_2, columns=[feature_cols[0:125]])\n","X_zero = df_zero\n","\n","# SCALED DATA\n","\n","df_x = training_data[feature_cols]\n","ss = StandardScaler()\n","df_x[feature_cols] = ss.fit_transform(df_x[feature_cols])\n","X_x = df_x\n","\n","# PCA WITH SCALED DATA\n","\n","df_z = df_x\n","pca2 = PCA(n_components=125, random_state=rand)\n","pca_2 = pca2.fit_transform(df_z)\n","df_z = pd.DataFrame(pca_2, columns=[feature_cols[0:125]])\n","X_z = df_z"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5r_B52kw4KAO"},"source":["##################################################################\n","#####################  METRICS FIRST  ############################\n","##################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RScdwXCNJ7m1"},"source":["def spearmanr(target, pred):\n","    return np.corrcoef(\n","        target,\n","        pred.rank(pct=True, method=\"first\")\n","    )[0, 1]\n","\n","def get_basic_per_era_metrics(df:pd.DataFrame, \n","                        isVal=None, \n","                        fig_name=\"per_era_scores.png\") -> pd.Series:\n","  \n","    prefix=None\n","    #Some checks for deciding between training and tournament data\n","    if isVal:\n","        df = df[df.data_type == \"validation\"]\n","        prefix=VAL_EVAL_PREFIX\n","        print(\"predicting on validation...\")\n","    else:\n","        df = df\n","        prefix=TRAIN_EVAL_PREFIX\n","        print(\"predicting on train...\")\n","\n","    #-----------------------------------------------------\n","    scores = pd.Series(dtype=float)\n","    preds_ = df[PREDICTION_NAME]\n","    scores[f\"{prefix}_mean\"] = preds_.mean()\n","    scores[f\"{prefix}_std_dev\"] = preds_.std()\n","\n","    #-----------------------------------------------------\n","    #Metric Calculations\n","    print(\"getting per era scores\")\n","    era_scores = df.groupby(\"era\").apply(\n","        lambda x: spearmanr(x[TARGET_NAME], x[PREDICTION_NAME]))\n","    \n","    era_scores.sort_index(inplace=True)\n","    era_scores.plot(kind=\"bar\")\n","    print(\"performance over time\")\n","    plt.pyplot.savefig(f\"{prefix}_{fig_name}\")\n","    plt.pyplot.show()\n","\n","    #-----------------------------------------------------\n","    scores[f\"{prefix}_mean correlation\"] = np.mean(era_scores)\n","    scores[f\"{prefix}_Std. Dev.\"] = np.std(era_scores)\n","    scores[f\"{prefix}_sharpe\"] = np.mean(era_scores)/np.std(era_scores)\n","\n","    print(scores)\n","    del era_scores\n","    del preds_\n","    \n","    gc.collect()\n","    return scores\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"okx5_Wi4khIM"},"source":["def get_all_metrics(model, \n","                    feature_names:list=feature_names, \n","                    fig_name=\"per_era_scores\")->pd.Series:\n","\n","    training_preds = model.predict(training_data[feature_names].values)\n","    training_data[PREDICTION_NAME] = np.array(training_preds).reshape(-1,1)\n","\n","    tournament_preds = model.predict(tournament_data[feature_names].values)\n","    tournament_data[PREDICTION_NAME] = np.array(tournament_preds).reshape(-1,1)\n","\n","    del training_preds\n","    del tournament_preds\n","\n","    print(\"evaluating on training data...\")\n","    tr_per_era_scores = get_basic_per_era_metrics(training_data, isVal=False, fig_name=fig_name)\n","    gc.collect()\n","\n","    print(\"evaluating on validation data...\")\n","    val_per_era_scores = get_basic_per_era_metrics(tournament_data, isVal=True, fig_name=fig_name)\n","    gc.collect()\n","\n","    return pd.concat([\n","                      tr_per_era_scores, val_per_era_scores,\n","                      ])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F9xZnXY7d8Bs"},"source":["#############################################################################\n","#############################  CREATING SOME MODELS   #######################\n","#############################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xiy3tWF07pgV","executionInfo":{"elapsed":967,"status":"ok","timestamp":1607171461860,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"},"user_tz":-60},"outputId":"df186529-181e-43ed-a2e5-e79e7520b9ed"},"source":["models = dict()\n","\n","#Linear model\n","lin_reg = LinearRegression()\n","models[\"lin_reg\"] = lin_reg\n","\n","#Neural Net\n","nn_model = tf.keras.models.Sequential([\n","                                       tf.keras.layers.Input(shape=(310,)),\n","                                       tf.keras.layers.Dense(64, activation=\"relu\"),\n","                                       tf.keras.layers.Dense(1, activation=\"sigmoid\")\n","])\n","nn_model.compile(loss=\"mse\", optimizer=\"adam\", metrics = [tf.keras.metrics.RootMeanSquaredError()])\n","\n","models[\"keras_mlp_simple\"] = nn_model\n","\n","#Neural Net Complex\n","\n","input_data = tf.keras.Input(shape=(len(feature_names),))\n","# tf.keras.layers.PReLU(alpha_initializer=\"zeros\", alpha_regularizer=None, alpha_constraint=None, shared_axes=None)\n","# tf.keras.layers.ELU(alpha=1.0)\n","# tf.keras.layers.ThresholdedReLU(theta=1.0)\n","# tf.keras.layers.LeakyReLU(alpha=0.3)\n","layer = tf.keras.layers.LeakyReLU(alpha=0.1)\n","final_layer = tf.keras.layers.Softmax(axis=-1)\n","x = tf.keras.layers.Dense(len(feature_names), activation=layer)(input_data)\n","x = tf.keras.layers.Dense(len(feature_names) // 2, activation=layer)(x)\n","x = tf.keras.layers.Dense(len(feature_names) // 4, activation=layer)(x)\n","output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n","optimizer = tf.keras.optimizers.Adam( learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\n","nn_model_complex = tf.keras.Model(input_data, output)\n","# model.compile(optimizer=optimizer, loss=pearson_cumsom_loss, metrics=['mae', 'mse'])\n","nn_model_complex.compile(optimizer=optimizer, loss=my_loss_fn, metrics=['mae', 'mse'])\n","\n","\n","models[\"keras_mlp_complex\"] = nn_model_complex\n","\n","\n","#CatBoost Regressor\n","cat_regressor = CatBoostRegressor()\n","models[\"cat_reg\"] = cat_regressor\n","\n","model_XGBRegressor = XGBRegressor(max_depth=10, learning_rate=0.01, n_estimators=2000, colsample_bytree=0.1, nthread=15)\n","models[\"model_XGB\"] = model_XGBRegressor\n","\n","\n","del lin_reg\n","del nn_model\n","del nn_model_complex\n","del cat_regressor\n","del model_XGBRegressor\n","\n","gc.collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["14"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oGaAr0vHzEMl","executionInfo":{"status":"ok","timestamp":1607172866950,"user_tz":-60,"elapsed":890,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"899c682c-3973-4616-b86c-938cf3d454f1"},"source":["models"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'cat_reg': <catboost.core.CatBoostRegressor at 0x7f92f6b92a20>,\n"," 'keras_mlp_complex': <tensorflow.python.keras.engine.functional.Functional at 0x7f92f67ceb70>,\n"," 'keras_mlp_simple': <tensorflow.python.keras.engine.sequential.Sequential at 0x7f92f6b15128>,\n"," 'lin_reg': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False),\n"," 'model_XGB': XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","              colsample_bynode=1, colsample_bytree=0.1, gamma=0,\n","              importance_type='gain', learning_rate=0.01, max_delta_step=0,\n","              max_depth=10, min_child_weight=1, missing=None, n_estimators=2000,\n","              n_jobs=1, nthread=15, objective='reg:linear', random_state=0,\n","              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n","              silent=None, subsample=1, verbosity=1)}"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"jvMY7xtKeIUs"},"source":["#############################################################################\n","####################   TRAINING OUR MODELS   ################################\n","#############################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"42sdknvqBg2Z"},"source":["for model_name in models:\n","    print(f\"Fitting {model_name}...\")\n","\n","    if \"keras\" in model_name:\n","        models[model_name].fit(training_data[feature_names].values, training_data[TARGET_NAME].values, \n","             batch_size=512, \n","             epochs=40,\n","             validation_data=(validation_data[feature_names].values, validation_data[TARGET_NAME].values),\n","             )\n","    else:\n","        models[model_name].fit(training_data[feature_names].values, training_data[TARGET_NAME].values)\n","\n","    gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ijzdbdbsIuKB","executionInfo":{"status":"ok","timestamp":1607173808195,"user_tz":-60,"elapsed":519,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"47d39fa8-f8fc-4624-cb27-14c0afc8ab40"},"source":["models"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'cat_reg': <catboost.core.CatBoostRegressor at 0x7f92f6b92a20>,\n"," 'keras_mlp_complex': <tensorflow.python.keras.engine.functional.Functional at 0x7f92f67ceb70>,\n"," 'keras_mlp_simple': <tensorflow.python.keras.engine.sequential.Sequential at 0x7f92f6b15128>,\n"," 'lin_reg': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False),\n"," 'model_XGB': XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","              colsample_bynode=1, colsample_bytree=0.1, gamma=0,\n","              importance_type='gain', learning_rate=0.01, max_delta_step=0,\n","              max_depth=10, min_child_weight=1, missing=None, n_estimators=2000,\n","              n_jobs=1, nthread=15, objective='reg:linear', random_state=0,\n","              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n","              silent=None, subsample=1, verbosity=1)}"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"TB1-07GPeQqf"},"source":["#############################################################################\n","##########################    EVALUATING MODELS    ##########################\n","#############################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sM563EctEM0g"},"source":["%%time\n","all_model_metrics = dict()\n","for model_name in models:\n","    \n","    print(f\"\\n----{model_name}----\")\n","    model_metrics = get_all_metrics(models[model_name], feature_names, fig_name = f\"{model_name}.png\")\n","    all_model_metrics[model_name] = model_metrics\n","\n","    gc.collect()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":348},"id":"C98Yl9f-BglX","executionInfo":{"status":"ok","timestamp":1607174110880,"user_tz":-60,"elapsed":560,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"c25e7850-8379-4a0d-ec42-8aafb933db7c"},"source":["metric_df = pd.DataFrame.from_dict(all_model_metrics)\n","metric_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lin_reg</th>\n","      <th>keras_mlp_simple</th>\n","      <th>keras_mlp_complex</th>\n","      <th>cat_reg</th>\n","      <th>model_XGB</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>train_mean</th>\n","      <td>0.500004</td>\n","      <td>0.503093</td>\n","      <td>0.504430</td>\n","      <td>0.499997</td>\n","      <td>0.499993</td>\n","    </tr>\n","    <tr>\n","      <th>train_std_dev</th>\n","      <td>0.011704</td>\n","      <td>0.036664</td>\n","      <td>0.107161</td>\n","      <td>0.024281</td>\n","      <td>0.058124</td>\n","    </tr>\n","    <tr>\n","      <th>train_mean correlation</th>\n","      <td>0.052274</td>\n","      <td>0.124772</td>\n","      <td>0.396850</td>\n","      <td>0.339578</td>\n","      <td>0.828164</td>\n","    </tr>\n","    <tr>\n","      <th>train_Std. Dev.</th>\n","      <td>0.030311</td>\n","      <td>0.024853</td>\n","      <td>0.023751</td>\n","      <td>0.023286</td>\n","      <td>0.012835</td>\n","    </tr>\n","    <tr>\n","      <th>train_sharpe</th>\n","      <td>1.724580</td>\n","      <td>5.020416</td>\n","      <td>16.708468</td>\n","      <td>14.582642</td>\n","      <td>64.525860</td>\n","    </tr>\n","    <tr>\n","      <th>val_mean</th>\n","      <td>0.500001</td>\n","      <td>0.503810</td>\n","      <td>0.507572</td>\n","      <td>0.501076</td>\n","      <td>0.500710</td>\n","    </tr>\n","    <tr>\n","      <th>val_std_dev</th>\n","      <td>0.011691</td>\n","      <td>0.039992</td>\n","      <td>0.111005</td>\n","      <td>0.022905</td>\n","      <td>0.022037</td>\n","    </tr>\n","    <tr>\n","      <th>val_mean correlation</th>\n","      <td>0.016143</td>\n","      <td>0.011350</td>\n","      <td>0.006056</td>\n","      <td>0.017243</td>\n","      <td>0.022210</td>\n","    </tr>\n","    <tr>\n","      <th>val_Std. Dev.</th>\n","      <td>0.029660</td>\n","      <td>0.019313</td>\n","      <td>0.019238</td>\n","      <td>0.025081</td>\n","      <td>0.027271</td>\n","    </tr>\n","    <tr>\n","      <th>val_sharpe</th>\n","      <td>0.544282</td>\n","      <td>0.587694</td>\n","      <td>0.314799</td>\n","      <td>0.687500</td>\n","      <td>0.814405</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         lin_reg  keras_mlp_simple  ...    cat_reg  model_XGB\n","train_mean              0.500004          0.503093  ...   0.499997   0.499993\n","train_std_dev           0.011704          0.036664  ...   0.024281   0.058124\n","train_mean correlation  0.052274          0.124772  ...   0.339578   0.828164\n","train_Std. Dev.         0.030311          0.024853  ...   0.023286   0.012835\n","train_sharpe            1.724580          5.020416  ...  14.582642  64.525860\n","val_mean                0.500001          0.503810  ...   0.501076   0.500710\n","val_std_dev             0.011691          0.039992  ...   0.022905   0.022037\n","val_mean correlation    0.016143          0.011350  ...   0.017243   0.022210\n","val_Std. Dev.           0.029660          0.019313  ...   0.025081   0.027271\n","val_sharpe              0.544282          0.587694  ...   0.687500   0.814405\n","\n","[10 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"fLl9fpob7kZp"},"source":["\n","- **`val_mean_correlation`** suggests how much your predictions are correlated to targets across `era`\n","- **`val_sharpe`** (mean/std) is for higher mean with lower std. dev.\n","- **`tournament_corr_example_preds`** shows how much your predictions are correlated with `example_predictions` (which have shown very good performance)\n","\n","As you can see, Neural Net is showing better performance here based on these metrics. Now, let's compare Neural Net with default CatBoost model on more metrics\n"]},{"cell_type":"code","metadata":{"id":"GDVneQHK5T2B"},"source":["##################################################################\n","#####################   MORE METRICS   ###########################\n","##################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WInhlaAl60of"},"source":["TRAIN_EVAL_PREFIX = \"train\"\n","VAL_EVAL_PREFIX = \"val\"\n","\n","#Some evaluation metrics\n","def ar1(x):\n","    return np.corrcoef(x[:-1], x[1:])[0,1]\n","\n","def autocorr_penalty(x):\n","    n = len(x)\n","    p = ar1(x)\n","    return np.sqrt(1 + 2*np.sum([((n - i)/n)*p**i for i in range(1,n)]))\n","\n","def smart_sharpe(x):\n","    return np.mean(x)/(np.std(x, ddof=1)*autocorr_penalty(x))\n","\n","def numerai_sharpe(x):\n","    return ((np.mean(x) - 0.010415154) / np.std(x)) * np.sqrt(12)\n","\n","def spearmanr(target, pred):\n","    return np.corrcoef(\n","        target,\n","        pred.rank(pct=True, method=\"first\")\n","    )[0, 1]\n","\n","#-----------------------------------------------------\n","def get_baisc_per_era_metrics(df:pd.DataFrame, \n","                        isVal=None, \n","                        fig_name=\"per_era_scores.png\") -> pd.Series:\n","    \n","    prefix=None\n","    scores = pd.Series(dtype=float)\n","\n","    preds_ = df[PREDICTION_NAME]\n","    #Some checks for deciding between training and tournament data\n","    if isVal:\n","        #scores[\"tournament_corr_example_preds\"] = spearmanr(preds_, example_preds[PREDICTION_NAME])\n","        df = df[df.data_type == \"validation\"]\n","        prefix=VAL_EVAL_PREFIX\n","        print(\"predicting on validation...\")\n","    else:\n","        df = df\n","        prefix=TRAIN_EVAL_PREFIX\n","        print(\"predicting on train...\")\n","\n","    #-----------------------------------------------------\n","\n","    #Metric Calculations\n","    print(\"getting per era scores\")\n","    era_scores = df.groupby(\"era\").apply(\n","        lambda x: spearmanr(x[TARGET_NAME], x[PREDICTION_NAME]))\n","    \n","    era_scores.sort_index(inplace=True)\n","    era_scores.plot(kind=\"bar\")\n","    print(\"performance over time\")\n","    plt.pyplot.savefig(f\"{prefix}_{fig_name}\")\n","    plt.pyplot.show()\n","\n","    #-----------------------------------------------------\n","    \n","    scores[f\"{prefix}_mean\"] = preds_.mean()\n","    scores[f\"{prefix}_std_dev\"] = preds_.std()\n","    scores[f\"{prefix}_less_than_half\"] = (preds_<0.5).mean()\n","    scores[f\"{prefix}_less_than_mean\"] = (preds_<preds_.mean()).mean()\n","\n","    scores[f\"{prefix}_autocorrelation\"] = ar1(era_scores)\n","    scores[f\"{prefix}_mean correlation\"] = np.mean(era_scores)\n","    scores[f\"{prefix}_Median Correlation\"] = np.median(era_scores)\n","    scores[f\"{prefix}_Variance\"] = np.var(era_scores)\n","    scores[f\"{prefix}_Std. Dev.\"] = np.std(era_scores)\n","    scores[f\"{prefix}_sharpe\"] = np.mean(era_scores)/np.std(era_scores)\n","    scores[f\"{prefix}_smart sharpe\"] = smart_sharpe(era_scores)\n","    scores[f\"{prefix}_Numerai sharpe\"] = numerai_sharpe(era_scores)\n","\n","    print(scores)\n","    del era_scores\n","    del preds_\n","    gc.collect()\n","    return scores\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a9A4b0HQ60kq"},"source":["def neutralize(df, columns, by, proportion=1.0):\n","    scores = df[columns]\n","    exposures = df[by].values\n","    \n","    # constant column to make sure the series is completely neutral to exposures\n","    exposures = np.hstack((exposures, np.array([np.mean(scores)] * len(exposures)).reshape(-1, 1)))\n","    gc.collect()\n","    scores = scores - proportion * exposures.dot(np.linalg.pinv(exposures).dot(scores))\n","    gc.collect()\n","    return scores / scores.std()\n","\n","\n","def calculate_feature_exposure(df, feature_names) -> list:\n","    exposures = []\n","    for feature_name in feature_names:\n","        exposures.append(spearmanr(df[feature_name], df[PREDICTION_NAME]))\n","        \n","    max_feat_exposure = np.max(np.abs(exposures))\n","    square_sum_feature_exposure = np.sum([e**2 for e in exposures])\n","    feature_exposure = np.std(exposures)\n","\n","    #print(max_feat_exposure, square_sum_feature_exposure)\n","\n","    return [feature_exposure, max_feat_exposure, square_sum_feature_exposure]\n","\n","\n","def get_more_metrics(df, feature_names, isVal=None) -> pd.Series:\n","    \n","    more_metrics = pd.Series(dtype=float)\n","    metric_prefix=None\n","    assert PREDICTION_NAME in df.columns\n","\n","    if isVal is None:\n","        isVal = \"validation\" in df[\"data_type\"].unique() #max CPU times: user 65.1 ms\n","\n","    print(isVal)\n","    if isVal:\n","        df = df[df[\"data_type\"]==\"validation\"]\n","        metric_prefix = VAL_EVAL_PREFIX\n","    else:\n","        metric_prefix = TRAIN_EVAL_PREFIX\n","\n","    assert metric_prefix is not None\n","\n","    #-----------------------------------------------------\n","\n","    #per-era scores\n","    \n","    print(\"predicting per-era scores...\")\n","    scores_per_era = df.groupby(\"era\").apply(\n","        lambda df: spearmanr(df[PREDICTION_NAME], df[TARGET_NAME]))\n","    \n","    more_metrics[f\"{metric_prefix}_var\"] = scores_per_era.std()\n","\n","    #-----------------------------------------------------\n","    \n","    #Neutralize\n","    #This takes a significant amount of memory for calculation\n","    print(df.shape)\n","    print(\"Neutralizing...\")\n","    df[f\"neutral_{PREDICTION_NAME}\"] = neutralize(df, PREDICTION_NAME, feature_names)\n","    feature_neutral_mean = df.groupby(\"era\").apply(\n","        lambda x: spearmanr(x[\"neutral_\"+PREDICTION_NAME].values, x[TARGET_NAME])).mean()\n","\n","    more_metrics[f\"{metric_prefix}_feature_neutral_mean\"] = feature_neutral_mean\n","    gc.collect()\n","\n","    #-----------------------------------------------------\n","    print(\"Calculating Feature Exposure...\")\n","    feature_exposure, max_feat_exposure, square_sum_feature_exposure = calculate_feature_exposure(df, feature_names)\n","\n","    more_metrics[f\"{metric_prefix}_feat_exposure\"] = feature_exposure\n","    more_metrics[f\"{metric_prefix}_max_feat_exposure\"] = max_feat_exposure\n","    more_metrics[f\"{metric_prefix}_square_sum_feature_exposure\"] = square_sum_feature_exposure\n","\n","\n","    #-----------------------------------------------------\n","    print(\"Drawdown...\")\n","    rolling_max = (scores_per_era+1).cumprod().rolling(window=100, min_periods=1).max()\n","    daily_value = (scores_per_era+1).cumprod()\n","    max_drawdown = (rolling_max - daily_value).max()\n","\n","    more_metrics[f\"{metric_prefix}_max_drawdown\"] = max_drawdown\n","\n","    return more_metrics"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wp9Gyg52DL6G"},"source":["def get_all_metrics(model, \n","                    feature_names:list=feature_names, \n","                    fig_name=\"per_era_scores\")->pd.Series:\n","\n","    training_preds = model.predict(training_data[feature_names].values)\n","    training_data[PREDICTION_NAME] = np.array(training_preds).reshape(-1,1)\n","\n","    tournament_preds = model.predict(tournament_data[feature_names].values)\n","    tournament_data[PREDICTION_NAME] = np.array(tournament_preds).reshape(-1,1)\n","\n","    del training_preds\n","    del tournament_preds\n","\n","    print(\"evaluating on training data...\")\n","    tr_per_era_scores = get_baisc_per_era_metrics(training_data, isVal=False, fig_name=fig_name)\n","    tr_more_metrics = get_more_metrics(training_data, feature_names ,isVal=False)\n","    gc.collect()\n","\n","    print(\"evaluating on validation data...\")\n","    val_per_era_scores = get_baisc_per_era_metrics(tournament_data, isVal=True, fig_name=fig_name)\n","    val_more_metrics = get_more_metrics(tournament_data, feature_names ,isVal=True)\n","    gc.collect()\n","\n","    return pd.concat([\n","                      tr_per_era_scores, val_per_era_scores,\n","                      tr_more_metrics, val_more_metrics,\n","                      ])\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p5T0pclBfLlF"},"source":["#############################################################################\n","###########################  CREATING SOME MODELS  ##########################\n","#############################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j0Kl9Ov0BVRH","executionInfo":{"status":"ok","timestamp":1607174251870,"user_tz":-60,"elapsed":792,"user":{"displayName":"Joan-Marc Fisa Gol","photoUrl":"","userId":"00374894131735723747"}},"outputId":"21836d50-9996-4e73-fa44-37fbe2be2bb4"},"source":["#Linear model\n","lin_reg = LinearRegression()\n","models[\"lin_reg\"] = lin_reg\n","\n","#Neural Net\n","nn_model = tf.keras.models.Sequential([\n","                                       tf.keras.layers.Input(shape=(310,)),\n","                                       tf.keras.layers.Dense(64, activation=\"relu\"),\n","                                       tf.keras.layers.Dense(1, activation=\"sigmoid\")\n","])\n","nn_model.compile(loss=\"mse\", optimizer=\"adam\", metrics = [tf.keras.metrics.RootMeanSquaredError()])\n","\n","models[\"keras_mlp_simple\"] = nn_model\n","\n","#Neural Net Complex\n","\n","input_data = tf.keras.Input(shape=(len(feature_names),))\n","# tf.keras.layers.PReLU(alpha_initializer=\"zeros\", alpha_regularizer=None, alpha_constraint=None, shared_axes=None)\n","# tf.keras.layers.ELU(alpha=1.0)\n","# tf.keras.layers.ThresholdedReLU(theta=1.0)\n","# tf.keras.layers.LeakyReLU(alpha=0.3)\n","layer = tf.keras.layers.LeakyReLU(alpha=0.1)\n","final_layer = tf.keras.layers.Softmax(axis=-1)\n","x = tf.keras.layers.Dense(len(feature_names), activation=layer)(input_data)\n","x = tf.keras.layers.Dense(len(feature_names) // 2, activation=layer)(x)\n","x = tf.keras.layers.Dense(len(feature_names) // 4, activation=layer)(x)\n","output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n","optimizer = tf.keras.optimizers.Adam( learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\n","nn_model_complex = tf.keras.Model(input_data, output)\n","# model.compile(optimizer=optimizer, loss=pearson_cumsom_loss, metrics=['mae', 'mse'])\n","nn_model_complex.compile(optimizer=optimizer, loss=my_loss_fn, metrics=['mae', 'mse'])\n","\n","\n","models[\"keras_mlp_complex\"] = nn_model_complex\n","\n","\n","#CatBoost Regressor\n","cat_regressor = CatBoostRegressor()\n","models[\"cat_reg\"] = cat_regressor\n","\n","model_XGBRegressor = XGBRegressor(max_depth=10, learning_rate=0.01, n_estimators=2000, colsample_bytree=0.1, nthread=15)\n","models[\"model_XGB\"] = model_XGBRegressor\n","\n","\n","del lin_reg\n","del nn_model\n","del nn_model_complex\n","del cat_regressor\n","del model_XGBRegressor\n","\n","gc.collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11992"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"roPmIdyl7F3T"},"source":["models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IWW_5irf7X-7"},"source":["#############################################################################\n","####################   TRAINING MORE MODELS   ###############################\n","#############################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_D3jvshpC3hW"},"source":["for model_name in models:\n","    print(f\"Fitting {model_name}...\")\n","\n","    if \"keras\" in model_name:\n","        models[model_name].fit(training_data[feature_names].values, training_data[TARGET_NAME].values, \n","             batch_size=512, \n","             epochs=40,\n","             validation_data=(validation_data[feature_names].values, validation_data[TARGET_NAME].values),\n","             )\n","    else:\n","        models[model_name].fit(training_data[feature_names].values, training_data[TARGET_NAME].values)\n","\n","    gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5VysffFoc43t"},"source":["##############################################################################\n","########################    EVALUATING MODELS    #############################\n","##############################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kOM9QWZ1J7aZ"},"source":["%%time\n","all_model_metrics = dict()\n","for model_name in models:\n","    \n","    print(f\"\\n----{model_name}----\")\n","    model_metrics = get_all_metrics(models[model_name], feature_names, fig_name = f\"{model_name}.png\")\n","    all_model_metrics[model_name] = model_metrics\n","    \n","    gc.collect()\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y8_GL_WXJ7VZ"},"source":["metric_df = pd.DataFrame.from_dict(all_model_metrics)\n","metric_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3d-tVasHcSxR"},"source":["##############################################################################\n","######################## MAKE PREDICTIONS ####################################\n","##############################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wYKGL_31Mz9o"},"source":["%%time\n","print(\"Generating predictions on training data...\")\n","training_preds = model.predict(training_data[feature_names].astype(np.float32))\n","training_data[PREDICTION_NAME] = training_preds\n","gc.collect()\n","\n","print(\"Generating predictions on tournament data...\")\n","tournament_preds = model.predict(tournament_data[feature_names].astype(np.float32))\n","tournament_data[PREDICTION_NAME] = tournament_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kW7y_UHyZAfa"},"source":["# Check the per-era correlations on the training set (in sample)\n","train_correlations = training_data.groupby(\"era\").apply(score)\n","print(f\"On training the correlation has mean {train_correlations.mean()} and std {train_correlations.std()}\")\n","print(f\"On training the average per-era payout is {payout(train_correlations).mean()}\")\n","\n","# Check the per-era correlations on the validation set (out of sample)\n","validation_data = tournament_data[tournament_data.data_type == \"validation\"]\n","validation_correlations = validation_data.groupby(\"era\").apply(score)\n","print(f\"On validation the correlation has mean {validation_correlations.mean()} and \"\n","        f\"std {validation_correlations.std()}\")\n","print(f\"On validation the average per-era payout is {payout(validation_correlations).mean()}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H0roqrT9ZAcH"},"source":["# FEAT_EXPOSURE: How much your model is correlated to the features across era\n","feature_exposures = validation_data[feature_names].apply(\n","    lambda d: correlation(validation_data[PREDICTION_NAME], d), axis=0\n",")\n","max_per_era = validation_data.groupby(\"era\").apply(\n","    lambda d: d[feature_names].corrwith(d[PREDICTION_NAME]).abs().max()\n",")\n","max_feature_exposure = max_per_era.mean()\n","print(f\"Max Feature Exposure: {max_feature_exposure}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"duMjwWrvbc2g"},"source":["print(\"Generating predictions...\")\n","    \n","torunament_features = tournament_data[feature_cols]\n","enc_Y_tournament = model.predict(torunament_features)\n","df_enc_Y_tournament = pd.DataFrame(enc_Y_tournament)\n","tournament_data[PREDICTION_NAME] = df_enc_Y_tournament\n","\n","print(\"Predictions Generated...\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQBQNRV2cm18"},"source":["##############################################################################\n","######################### MAKE SUBMISSION #################################### \n","##############################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dNlyLZYYO-qj"},"source":["tournament_data[PREDICTION_NAME].to_csv(f\"{TOURNAMENT_NAME}_{current_ds}_submission.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rEfqpxcEWDdK"},"source":["# NameOfYourAI\n","public_id = \"7TISUDGAWEVO2B35ECOQQXU2RWXGZN3I\"\n","secret_key = \"QJYUWIMFEEDNZ4GHUO6VSSKPMRCBFJIMJ7BZ65ESIWRN4YHGYHSRJDNL64TAG7EH\"\n","model_id = \"d49c26a4-aa5b-4490-9d58-300c5e05d996\"\n","napi = numerapi.NumerAPI(public_id=public_id, secret_key=secret_key)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WeAIJHaoW3VU"},"source":["submission_id = napi.upload_predictions(f\"{TOURNAMENT_NAME}_{current_ds}_submission.csv\", model_id=model_id)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VvFwjBq0WO-2"},"source":["print(\"Generating Public_ID and Model_ID...\")\n","# Get your API keys and model_id from https://numer.ai/submit\n","public_id = \"7TISUDGAWEVO2B35ECOQQXU2RWXGZN3I\"\n","secret_key = \"QJYUWIMFEEDNZ4GHUO6VSSKPMRCBFJIMJ7BZ65ESIWRN4YHGYHSRJDNL64TAG7EH\"\n","model_id = \"d49c26a4-aa5b-4490-9d58-300c5e05d996\"\n","napi = numerapi.NumerAPI(public_id=public_id, secret_key=secret_key)\n","print(\"Generated!\")\n","\n","print(\"Generating DataFrame to submission...\")\n","predictions_df = tournament_data[\"id\"].to_frame()\n","predictions_df[\"prediction\"] = tournament_data[PREDICTION_NAME]\n","print(\"Generated!\")\n","\n","print(\"Uploading DataFrame in Numerai...\")\n","# Upload your predictions\n","predictions_df.to_csv(\"predictions.csv\", index=False)\n","submission_id = napi.upload_predictions(\"predictions.csv\", model_id=model_id)\n","print(\"DataFrame Uploaded...\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KIxCcUu5bqUf"},"source":["##############################################################################\n","########################  SAVE AND LOAD THE MODEL  ###########################\n","##############################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pydxKpa6ctSM"},"source":["# SAVE MODEL\n","model.save_weights('numeraiThe_Model.h5', overwrite=True, save_format=None, options=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ZWJn9FMbqaA"},"source":["# LOAD MODEL\n","model.load_weights('numeraiThe_Model.h5', by_name=False, skip_mismatch=False, options=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iZ0OKy4_bqXq"},"source":[""],"execution_count":null,"outputs":[]}]}